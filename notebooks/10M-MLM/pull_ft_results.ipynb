{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdf3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed722789",
   "metadata": {},
   "source": [
    "Load in `.csv` file that came from `stage-p2x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283d7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('runs_with_eval_loss_and_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf98498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>min_eval_loss</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>attention_probs_dropout_prob</th>\n",
       "      <th>hidden_dropout_prob</th>\n",
       "      <th>intermediate_size</th>\n",
       "      <th>num_attention_heads</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>pretraining_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.615919</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_34</td>\n",
       "      <td>0.131611</td>\n",
       "      <td>696</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.226</td>\n",
       "      <td>8436</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>10M-MLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_2</td>\n",
       "      <td>0.172452</td>\n",
       "      <td>82</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.160</td>\n",
       "      <td>11024</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>10M-MLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.457947</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>10M-MLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>10M-MLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>run_43</td>\n",
       "      <td>0.158320</td>\n",
       "      <td>324</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.126</td>\n",
       "      <td>5428</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>10M-MLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>run_4</td>\n",
       "      <td>0.711699</td>\n",
       "      <td>344</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.139</td>\n",
       "      <td>1252</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>10M-MLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10M-MLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>run_9</td>\n",
       "      <td>0.149599</td>\n",
       "      <td>580</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.121</td>\n",
       "      <td>5712</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>10M-MLM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  run_name  min_eval_loss  hidden_size  attention_probs_dropout_prob  \\\n",
       "0   run_39       0.429169          209                         0.176   \n",
       "1   run_11       0.615919          112                         0.118   \n",
       "2   run_34       0.131611          696                         0.148   \n",
       "3    run_2       0.172452           82                         0.232   \n",
       "4   run_38       0.457947          126                         0.109   \n",
       "5   run_45       0.147017          384                         0.109   \n",
       "6   run_43       0.158320          324                         0.201   \n",
       "7    run_4       0.711699          344                         0.235   \n",
       "8   run_19       0.196440           57                         0.129   \n",
       "9    run_9       0.149599          580                         0.249   \n",
       "\n",
       "   hidden_dropout_prob  intermediate_size  num_attention_heads  \\\n",
       "0                0.128               3968                   11   \n",
       "1                0.183               4844                    8   \n",
       "2                0.226               8436                   12   \n",
       "3                0.160              11024                    2   \n",
       "4                0.279                456                    3   \n",
       "5                0.144                464                   12   \n",
       "6                0.126               5428                    9   \n",
       "7                0.139               1252                    8   \n",
       "8                0.139              10476                    3   \n",
       "9                0.121               5712                   10   \n",
       "\n",
       "   num_hidden_layers  learning_rate pretraining_task  \n",
       "0                  3       0.000002          10M-MLM  \n",
       "1                  5       0.000002          10M-MLM  \n",
       "2                  2       0.000087          10M-MLM  \n",
       "3                  6       0.000144          10M-MLM  \n",
       "4                  2       0.000021          10M-MLM  \n",
       "5                  3       0.000141          10M-MLM  \n",
       "6                  2       0.000262          10M-MLM  \n",
       "7                  4       0.000003          10M-MLM  \n",
       "8                  5       0.000058          10M-MLM  \n",
       "9                  3       0.000279          10M-MLM  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09636bc",
   "metadata": {},
   "source": [
    "Load in data from MolNet finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa934af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc636a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b63783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5760bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bucket = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a504eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_dir = f\"s3://{model_bucket}/chemberta/mlm_pretraining_10M_20210723/molnet_mlm_10M_ft_20210723/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40e2f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(cloud_dir):\n",
    "    run_dirs = fs.ls(cloud_dir)\n",
    "    data_avg = []\n",
    "    df_all = pd.DataFrame()\n",
    "    for rd in run_dirs:\n",
    "        run_name = os.path.basename(os.path.normpath(rd))\n",
    "        # go one level down to get the molnet task\n",
    "        molnet_task_data_avg = {}\n",
    "        molnet_task_data_all = {}\n",
    "        for molnet_task_dir in fs.ls(rd):\n",
    "            molnet_task_name = os.path.basename(os.path.normpath(molnet_task_dir))\n",
    "            results_dir = os.path.join(molnet_task_dir, \"results/\")\n",
    "            for subset in [\"valid\", \"test\"]:\n",
    "                with fs.open(os.path.join(results_dir, subset, \"metrics.json\")) as f:\n",
    "                    metrics = json.load(f)\n",
    "                # pick first item to get the keys\n",
    "                metric_names = list(list(metrics.items())[0][1].keys())\n",
    "                metric_res = {mn: [] for mn in metric_names}\n",
    "                for seed, res in metrics.items():\n",
    "                    for mn, mres in res.items():\n",
    "                        if mn == \"pearsonr\":\n",
    "                            metric_res[mn].append(mres[0])\n",
    "                        else:\n",
    "                            metric_res[mn].append(mres)\n",
    "                molnet_task_data_all.update({f\"{molnet_task_name}_{subset}_{mn}\": metric_res[mn] for mn in metric_names})\n",
    "                average_metrics = {f\"{molnet_task_name}_{subset}_{mn}_mean\": np.mean(metric_res[mn]) for mn in metric_names}\n",
    "                std_metrics = {f\"{molnet_task_name}_{subset}_{mn}_std\": np.std(metric_res[mn]) for mn in metric_names}\n",
    "                molnet_task_data_avg.update({**average_metrics, **std_metrics})\n",
    "        molnet_task_data_all.update({\"run_name\": [run_name]*5})\n",
    "        df_all = df_all.append(pd.DataFrame(molnet_task_data_all))\n",
    "        data_avg.append({\"run_name\": run_name, **molnet_task_data_avg})\n",
    "\n",
    "    df_avg = pd.DataFrame(data_avg)\n",
    "    return df_all, df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c3518c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all, df_avg = get_dataframes(cloud_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "235036ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bace_classification_valid_roc_auc_score</th>\n",
       "      <th>bace_classification_valid_average_precision_score</th>\n",
       "      <th>bace_classification_test_roc_auc_score</th>\n",
       "      <th>bace_classification_test_average_precision_score</th>\n",
       "      <th>bace_regression_valid_pearsonr</th>\n",
       "      <th>bace_regression_valid_rmse</th>\n",
       "      <th>bace_regression_test_pearsonr</th>\n",
       "      <th>bace_regression_test_rmse</th>\n",
       "      <th>bbbp_valid_roc_auc_score</th>\n",
       "      <th>bbbp_valid_average_precision_score</th>\n",
       "      <th>...</th>\n",
       "      <th>delaney_test_rmse</th>\n",
       "      <th>lipo_valid_pearsonr</th>\n",
       "      <th>lipo_valid_rmse</th>\n",
       "      <th>lipo_test_pearsonr</th>\n",
       "      <th>lipo_test_rmse</th>\n",
       "      <th>tox21_valid_roc_auc_score</th>\n",
       "      <th>tox21_valid_average_precision_score</th>\n",
       "      <th>tox21_test_roc_auc_score</th>\n",
       "      <th>tox21_test_average_precision_score</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.622246</td>\n",
       "      <td>0.692692</td>\n",
       "      <td>0.793841</td>\n",
       "      <td>0.862725</td>\n",
       "      <td>-0.230438</td>\n",
       "      <td>0.596198</td>\n",
       "      <td>-0.217982</td>\n",
       "      <td>1.276962</td>\n",
       "      <td>0.558036</td>\n",
       "      <td>0.639609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602184</td>\n",
       "      <td>0.576544</td>\n",
       "      <td>0.823305</td>\n",
       "      <td>0.512566</td>\n",
       "      <td>0.806596</td>\n",
       "      <td>0.762783</td>\n",
       "      <td>0.412171</td>\n",
       "      <td>0.729537</td>\n",
       "      <td>0.286098</td>\n",
       "      <td>run_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617271</td>\n",
       "      <td>0.649605</td>\n",
       "      <td>0.772101</td>\n",
       "      <td>0.814909</td>\n",
       "      <td>-0.229989</td>\n",
       "      <td>0.595898</td>\n",
       "      <td>-0.216031</td>\n",
       "      <td>1.276871</td>\n",
       "      <td>0.557793</td>\n",
       "      <td>0.639575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538507</td>\n",
       "      <td>0.590941</td>\n",
       "      <td>0.813351</td>\n",
       "      <td>0.524219</td>\n",
       "      <td>0.790027</td>\n",
       "      <td>0.761239</td>\n",
       "      <td>0.368507</td>\n",
       "      <td>0.741719</td>\n",
       "      <td>0.285398</td>\n",
       "      <td>run_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.618515</td>\n",
       "      <td>0.651651</td>\n",
       "      <td>0.768659</td>\n",
       "      <td>0.818526</td>\n",
       "      <td>-0.230389</td>\n",
       "      <td>0.596087</td>\n",
       "      <td>-0.219816</td>\n",
       "      <td>1.276949</td>\n",
       "      <td>0.557939</td>\n",
       "      <td>0.639505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541780</td>\n",
       "      <td>0.602478</td>\n",
       "      <td>0.807255</td>\n",
       "      <td>0.505320</td>\n",
       "      <td>0.812510</td>\n",
       "      <td>0.734858</td>\n",
       "      <td>0.433442</td>\n",
       "      <td>0.745780</td>\n",
       "      <td>0.299844</td>\n",
       "      <td>run_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.643390</td>\n",
       "      <td>0.703720</td>\n",
       "      <td>0.809601</td>\n",
       "      <td>0.868508</td>\n",
       "      <td>-0.230280</td>\n",
       "      <td>0.595910</td>\n",
       "      <td>-0.218276</td>\n",
       "      <td>1.276893</td>\n",
       "      <td>0.557648</td>\n",
       "      <td>0.639309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568094</td>\n",
       "      <td>0.556328</td>\n",
       "      <td>0.835626</td>\n",
       "      <td>0.447331</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.762268</td>\n",
       "      <td>0.433016</td>\n",
       "      <td>0.737609</td>\n",
       "      <td>0.343815</td>\n",
       "      <td>run_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629353</td>\n",
       "      <td>0.699278</td>\n",
       "      <td>0.768841</td>\n",
       "      <td>0.829362</td>\n",
       "      <td>-0.230689</td>\n",
       "      <td>0.596143</td>\n",
       "      <td>-0.219356</td>\n",
       "      <td>1.276957</td>\n",
       "      <td>0.558036</td>\n",
       "      <td>0.639608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>0.569293</td>\n",
       "      <td>0.827344</td>\n",
       "      <td>0.491301</td>\n",
       "      <td>0.799713</td>\n",
       "      <td>0.785904</td>\n",
       "      <td>0.453306</td>\n",
       "      <td>0.746074</td>\n",
       "      <td>0.306306</td>\n",
       "      <td>run_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.520611</td>\n",
       "      <td>0.591752</td>\n",
       "      <td>0.580978</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>0.268872</td>\n",
       "      <td>0.567899</td>\n",
       "      <td>0.653381</td>\n",
       "      <td>1.199541</td>\n",
       "      <td>0.591421</td>\n",
       "      <td>0.696895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720130</td>\n",
       "      <td>0.660857</td>\n",
       "      <td>0.759722</td>\n",
       "      <td>0.582182</td>\n",
       "      <td>0.750324</td>\n",
       "      <td>0.735308</td>\n",
       "      <td>0.404245</td>\n",
       "      <td>0.730173</td>\n",
       "      <td>0.378770</td>\n",
       "      <td>run_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.520789</td>\n",
       "      <td>0.591859</td>\n",
       "      <td>0.580978</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>0.343638</td>\n",
       "      <td>0.559259</td>\n",
       "      <td>0.672247</td>\n",
       "      <td>1.170662</td>\n",
       "      <td>0.593071</td>\n",
       "      <td>0.690113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721768</td>\n",
       "      <td>0.670714</td>\n",
       "      <td>0.746713</td>\n",
       "      <td>0.624257</td>\n",
       "      <td>0.717793</td>\n",
       "      <td>0.730268</td>\n",
       "      <td>0.414122</td>\n",
       "      <td>0.712804</td>\n",
       "      <td>0.345822</td>\n",
       "      <td>run_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.520611</td>\n",
       "      <td>0.591752</td>\n",
       "      <td>0.580978</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>0.353859</td>\n",
       "      <td>0.561093</td>\n",
       "      <td>0.675618</td>\n",
       "      <td>1.165820</td>\n",
       "      <td>0.589383</td>\n",
       "      <td>0.691106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712005</td>\n",
       "      <td>0.697282</td>\n",
       "      <td>0.730289</td>\n",
       "      <td>0.663698</td>\n",
       "      <td>0.696253</td>\n",
       "      <td>0.709463</td>\n",
       "      <td>0.432810</td>\n",
       "      <td>0.715593</td>\n",
       "      <td>0.341018</td>\n",
       "      <td>run_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.520789</td>\n",
       "      <td>0.591798</td>\n",
       "      <td>0.580978</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>0.319156</td>\n",
       "      <td>0.566845</td>\n",
       "      <td>0.683307</td>\n",
       "      <td>1.181743</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.695128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729394</td>\n",
       "      <td>0.675801</td>\n",
       "      <td>0.747815</td>\n",
       "      <td>0.633899</td>\n",
       "      <td>0.718338</td>\n",
       "      <td>0.700969</td>\n",
       "      <td>0.360835</td>\n",
       "      <td>0.724546</td>\n",
       "      <td>0.379368</td>\n",
       "      <td>run_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520611</td>\n",
       "      <td>0.589814</td>\n",
       "      <td>0.580978</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>0.313719</td>\n",
       "      <td>0.568147</td>\n",
       "      <td>0.665972</td>\n",
       "      <td>1.191766</td>\n",
       "      <td>0.593168</td>\n",
       "      <td>0.688426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723447</td>\n",
       "      <td>0.654816</td>\n",
       "      <td>0.768090</td>\n",
       "      <td>0.565669</td>\n",
       "      <td>0.759907</td>\n",
       "      <td>0.722268</td>\n",
       "      <td>0.380278</td>\n",
       "      <td>0.722491</td>\n",
       "      <td>0.316989</td>\n",
       "      <td>run_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655828</td>\n",
       "      <td>0.661141</td>\n",
       "      <td>0.652899</td>\n",
       "      <td>0.747142</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.581904</td>\n",
       "      <td>0.191228</td>\n",
       "      <td>1.252637</td>\n",
       "      <td>0.952640</td>\n",
       "      <td>0.955222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566598</td>\n",
       "      <td>0.695097</td>\n",
       "      <td>0.750743</td>\n",
       "      <td>0.680795</td>\n",
       "      <td>0.696812</td>\n",
       "      <td>0.770290</td>\n",
       "      <td>0.429965</td>\n",
       "      <td>0.752287</td>\n",
       "      <td>0.392007</td>\n",
       "      <td>run_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680881</td>\n",
       "      <td>0.680280</td>\n",
       "      <td>0.721377</td>\n",
       "      <td>0.787215</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.581772</td>\n",
       "      <td>0.191372</td>\n",
       "      <td>1.252585</td>\n",
       "      <td>0.952252</td>\n",
       "      <td>0.952802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537460</td>\n",
       "      <td>0.723588</td>\n",
       "      <td>0.727463</td>\n",
       "      <td>0.713709</td>\n",
       "      <td>0.677001</td>\n",
       "      <td>0.769775</td>\n",
       "      <td>0.427343</td>\n",
       "      <td>0.752777</td>\n",
       "      <td>0.402069</td>\n",
       "      <td>run_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.712331</td>\n",
       "      <td>0.705858</td>\n",
       "      <td>0.775543</td>\n",
       "      <td>0.822413</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.191324</td>\n",
       "      <td>1.252603</td>\n",
       "      <td>0.951766</td>\n",
       "      <td>0.954098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544972</td>\n",
       "      <td>0.712785</td>\n",
       "      <td>0.730614</td>\n",
       "      <td>0.702685</td>\n",
       "      <td>0.676545</td>\n",
       "      <td>0.772049</td>\n",
       "      <td>0.429428</td>\n",
       "      <td>0.755908</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>run_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.673952</td>\n",
       "      <td>0.676048</td>\n",
       "      <td>0.734601</td>\n",
       "      <td>0.794156</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>0.581820</td>\n",
       "      <td>0.191308</td>\n",
       "      <td>1.252617</td>\n",
       "      <td>0.954387</td>\n",
       "      <td>0.956743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544419</td>\n",
       "      <td>0.711281</td>\n",
       "      <td>0.742473</td>\n",
       "      <td>0.701187</td>\n",
       "      <td>0.683299</td>\n",
       "      <td>0.766730</td>\n",
       "      <td>0.428032</td>\n",
       "      <td>0.750330</td>\n",
       "      <td>0.381192</td>\n",
       "      <td>run_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.706290</td>\n",
       "      <td>0.701382</td>\n",
       "      <td>0.769746</td>\n",
       "      <td>0.824203</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>0.581709</td>\n",
       "      <td>0.191345</td>\n",
       "      <td>1.252582</td>\n",
       "      <td>0.953610</td>\n",
       "      <td>0.955316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558833</td>\n",
       "      <td>0.718250</td>\n",
       "      <td>0.724182</td>\n",
       "      <td>0.706217</td>\n",
       "      <td>0.674961</td>\n",
       "      <td>0.771577</td>\n",
       "      <td>0.429924</td>\n",
       "      <td>0.750917</td>\n",
       "      <td>0.390249</td>\n",
       "      <td>run_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.471926</td>\n",
       "      <td>0.567811</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.633643</td>\n",
       "      <td>0.166033</td>\n",
       "      <td>0.555100</td>\n",
       "      <td>0.517352</td>\n",
       "      <td>1.179242</td>\n",
       "      <td>0.404697</td>\n",
       "      <td>0.530489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627140</td>\n",
       "      <td>0.580184</td>\n",
       "      <td>0.827611</td>\n",
       "      <td>0.510875</td>\n",
       "      <td>0.805915</td>\n",
       "      <td>0.739662</td>\n",
       "      <td>0.390483</td>\n",
       "      <td>0.761975</td>\n",
       "      <td>0.334774</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.471748</td>\n",
       "      <td>0.567763</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.633643</td>\n",
       "      <td>0.201710</td>\n",
       "      <td>0.549131</td>\n",
       "      <td>0.533566</td>\n",
       "      <td>1.149470</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>0.530453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626971</td>\n",
       "      <td>0.568434</td>\n",
       "      <td>0.832074</td>\n",
       "      <td>0.503531</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>0.741421</td>\n",
       "      <td>0.419757</td>\n",
       "      <td>0.753804</td>\n",
       "      <td>0.325718</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.471926</td>\n",
       "      <td>0.567811</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.633643</td>\n",
       "      <td>0.172848</td>\n",
       "      <td>0.546964</td>\n",
       "      <td>0.514231</td>\n",
       "      <td>1.190567</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>0.530453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633649</td>\n",
       "      <td>0.572446</td>\n",
       "      <td>0.827933</td>\n",
       "      <td>0.470739</td>\n",
       "      <td>0.836043</td>\n",
       "      <td>0.738418</td>\n",
       "      <td>0.435662</td>\n",
       "      <td>0.750183</td>\n",
       "      <td>0.348128</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.471926</td>\n",
       "      <td>0.567811</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.633643</td>\n",
       "      <td>0.170554</td>\n",
       "      <td>0.552603</td>\n",
       "      <td>0.542227</td>\n",
       "      <td>1.164638</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>0.530453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623227</td>\n",
       "      <td>0.584919</td>\n",
       "      <td>0.828532</td>\n",
       "      <td>0.528177</td>\n",
       "      <td>0.788722</td>\n",
       "      <td>0.740520</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.766574</td>\n",
       "      <td>0.373289</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.471926</td>\n",
       "      <td>0.567811</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.633643</td>\n",
       "      <td>0.181692</td>\n",
       "      <td>0.554777</td>\n",
       "      <td>0.509093</td>\n",
       "      <td>1.186495</td>\n",
       "      <td>0.404697</td>\n",
       "      <td>0.530489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646044</td>\n",
       "      <td>0.582805</td>\n",
       "      <td>0.823751</td>\n",
       "      <td>0.529007</td>\n",
       "      <td>0.794890</td>\n",
       "      <td>0.716970</td>\n",
       "      <td>0.382302</td>\n",
       "      <td>0.736093</td>\n",
       "      <td>0.346758</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.691720</td>\n",
       "      <td>0.696676</td>\n",
       "      <td>0.732428</td>\n",
       "      <td>0.777886</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>0.592910</td>\n",
       "      <td>0.034643</td>\n",
       "      <td>1.274042</td>\n",
       "      <td>0.266984</td>\n",
       "      <td>0.409481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509745</td>\n",
       "      <td>0.645184</td>\n",
       "      <td>0.769643</td>\n",
       "      <td>0.531337</td>\n",
       "      <td>0.782116</td>\n",
       "      <td>0.782730</td>\n",
       "      <td>0.409358</td>\n",
       "      <td>0.724644</td>\n",
       "      <td>0.319663</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.694030</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.705797</td>\n",
       "      <td>0.775385</td>\n",
       "      <td>-0.003292</td>\n",
       "      <td>0.592905</td>\n",
       "      <td>0.034240</td>\n",
       "      <td>1.274052</td>\n",
       "      <td>0.267178</td>\n",
       "      <td>0.409545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469569</td>\n",
       "      <td>0.599654</td>\n",
       "      <td>0.806719</td>\n",
       "      <td>0.514140</td>\n",
       "      <td>0.788926</td>\n",
       "      <td>0.761625</td>\n",
       "      <td>0.408209</td>\n",
       "      <td>0.771858</td>\n",
       "      <td>0.277485</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.688699</td>\n",
       "      <td>0.696747</td>\n",
       "      <td>0.665580</td>\n",
       "      <td>0.750406</td>\n",
       "      <td>-0.002621</td>\n",
       "      <td>0.593019</td>\n",
       "      <td>0.033375</td>\n",
       "      <td>1.274098</td>\n",
       "      <td>0.266984</td>\n",
       "      <td>0.409483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512288</td>\n",
       "      <td>0.609248</td>\n",
       "      <td>0.797949</td>\n",
       "      <td>0.509164</td>\n",
       "      <td>0.795617</td>\n",
       "      <td>0.769647</td>\n",
       "      <td>0.426420</td>\n",
       "      <td>0.751504</td>\n",
       "      <td>0.299939</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.685679</td>\n",
       "      <td>0.696990</td>\n",
       "      <td>0.770109</td>\n",
       "      <td>0.812954</td>\n",
       "      <td>-0.003633</td>\n",
       "      <td>0.593103</td>\n",
       "      <td>0.034745</td>\n",
       "      <td>1.274085</td>\n",
       "      <td>0.267275</td>\n",
       "      <td>0.409589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484284</td>\n",
       "      <td>0.586889</td>\n",
       "      <td>0.815365</td>\n",
       "      <td>0.503509</td>\n",
       "      <td>0.800754</td>\n",
       "      <td>0.776381</td>\n",
       "      <td>0.431358</td>\n",
       "      <td>0.738343</td>\n",
       "      <td>0.287014</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.685501</td>\n",
       "      <td>0.691702</td>\n",
       "      <td>0.719203</td>\n",
       "      <td>0.780523</td>\n",
       "      <td>-0.002773</td>\n",
       "      <td>0.592951</td>\n",
       "      <td>0.033617</td>\n",
       "      <td>1.274074</td>\n",
       "      <td>0.267275</td>\n",
       "      <td>0.409577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541653</td>\n",
       "      <td>0.604970</td>\n",
       "      <td>0.804004</td>\n",
       "      <td>0.507554</td>\n",
       "      <td>0.796507</td>\n",
       "      <td>0.780156</td>\n",
       "      <td>0.400269</td>\n",
       "      <td>0.740154</td>\n",
       "      <td>0.308734</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633618</td>\n",
       "      <td>0.679400</td>\n",
       "      <td>0.800725</td>\n",
       "      <td>0.836683</td>\n",
       "      <td>0.181056</td>\n",
       "      <td>0.536392</td>\n",
       "      <td>0.741226</td>\n",
       "      <td>1.068135</td>\n",
       "      <td>0.969915</td>\n",
       "      <td>0.966442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441218</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.705519</td>\n",
       "      <td>0.722884</td>\n",
       "      <td>0.665679</td>\n",
       "      <td>0.783717</td>\n",
       "      <td>0.472981</td>\n",
       "      <td>0.740594</td>\n",
       "      <td>0.352845</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.641613</td>\n",
       "      <td>0.687703</td>\n",
       "      <td>0.810507</td>\n",
       "      <td>0.842201</td>\n",
       "      <td>0.178669</td>\n",
       "      <td>0.538551</td>\n",
       "      <td>0.725300</td>\n",
       "      <td>1.119912</td>\n",
       "      <td>0.969915</td>\n",
       "      <td>0.964857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435431</td>\n",
       "      <td>0.740711</td>\n",
       "      <td>0.735474</td>\n",
       "      <td>0.717953</td>\n",
       "      <td>0.696740</td>\n",
       "      <td>0.786676</td>\n",
       "      <td>0.469447</td>\n",
       "      <td>0.732325</td>\n",
       "      <td>0.357853</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641080</td>\n",
       "      <td>0.683514</td>\n",
       "      <td>0.807609</td>\n",
       "      <td>0.839962</td>\n",
       "      <td>0.175059</td>\n",
       "      <td>0.544611</td>\n",
       "      <td>0.715257</td>\n",
       "      <td>1.144432</td>\n",
       "      <td>0.970303</td>\n",
       "      <td>0.966205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436801</td>\n",
       "      <td>0.749266</td>\n",
       "      <td>0.700821</td>\n",
       "      <td>0.733807</td>\n",
       "      <td>0.657533</td>\n",
       "      <td>0.777239</td>\n",
       "      <td>0.451759</td>\n",
       "      <td>0.745389</td>\n",
       "      <td>0.366156</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.643390</td>\n",
       "      <td>0.683800</td>\n",
       "      <td>0.810507</td>\n",
       "      <td>0.842051</td>\n",
       "      <td>0.175182</td>\n",
       "      <td>0.539764</td>\n",
       "      <td>0.727938</td>\n",
       "      <td>1.126450</td>\n",
       "      <td>0.969235</td>\n",
       "      <td>0.963910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435814</td>\n",
       "      <td>0.744456</td>\n",
       "      <td>0.712699</td>\n",
       "      <td>0.712487</td>\n",
       "      <td>0.683005</td>\n",
       "      <td>0.755920</td>\n",
       "      <td>0.419479</td>\n",
       "      <td>0.734185</td>\n",
       "      <td>0.352519</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.640014</td>\n",
       "      <td>0.682155</td>\n",
       "      <td>0.808514</td>\n",
       "      <td>0.840243</td>\n",
       "      <td>0.185213</td>\n",
       "      <td>0.536827</td>\n",
       "      <td>0.738607</td>\n",
       "      <td>1.089087</td>\n",
       "      <td>0.968847</td>\n",
       "      <td>0.963658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448837</td>\n",
       "      <td>0.720865</td>\n",
       "      <td>0.734076</td>\n",
       "      <td>0.692787</td>\n",
       "      <td>0.692444</td>\n",
       "      <td>0.780285</td>\n",
       "      <td>0.474502</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.358638</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bace_classification_valid_roc_auc_score  \\\n",
       "0                                 0.622246   \n",
       "1                                 0.617271   \n",
       "2                                 0.618515   \n",
       "3                                 0.643390   \n",
       "4                                 0.629353   \n",
       "0                                 0.520611   \n",
       "1                                 0.520789   \n",
       "2                                 0.520611   \n",
       "3                                 0.520789   \n",
       "4                                 0.520611   \n",
       "0                                 0.655828   \n",
       "1                                 0.680881   \n",
       "2                                 0.712331   \n",
       "3                                 0.673952   \n",
       "4                                 0.706290   \n",
       "0                                 0.471926   \n",
       "1                                 0.471748   \n",
       "2                                 0.471926   \n",
       "3                                 0.471926   \n",
       "4                                 0.471926   \n",
       "0                                 0.691720   \n",
       "1                                 0.694030   \n",
       "2                                 0.688699   \n",
       "3                                 0.685679   \n",
       "4                                 0.685501   \n",
       "0                                 0.633618   \n",
       "1                                 0.641613   \n",
       "2                                 0.641080   \n",
       "3                                 0.643390   \n",
       "4                                 0.640014   \n",
       "\n",
       "   bace_classification_valid_average_precision_score  \\\n",
       "0                                           0.692692   \n",
       "1                                           0.649605   \n",
       "2                                           0.651651   \n",
       "3                                           0.703720   \n",
       "4                                           0.699278   \n",
       "0                                           0.591752   \n",
       "1                                           0.591859   \n",
       "2                                           0.591752   \n",
       "3                                           0.591798   \n",
       "4                                           0.589814   \n",
       "0                                           0.661141   \n",
       "1                                           0.680280   \n",
       "2                                           0.705858   \n",
       "3                                           0.676048   \n",
       "4                                           0.701382   \n",
       "0                                           0.567811   \n",
       "1                                           0.567763   \n",
       "2                                           0.567811   \n",
       "3                                           0.567811   \n",
       "4                                           0.567811   \n",
       "0                                           0.696676   \n",
       "1                                           0.704329   \n",
       "2                                           0.696747   \n",
       "3                                           0.696990   \n",
       "4                                           0.691702   \n",
       "0                                           0.679400   \n",
       "1                                           0.687703   \n",
       "2                                           0.683514   \n",
       "3                                           0.683800   \n",
       "4                                           0.682155   \n",
       "\n",
       "   bace_classification_test_roc_auc_score  \\\n",
       "0                                0.793841   \n",
       "1                                0.772101   \n",
       "2                                0.768659   \n",
       "3                                0.809601   \n",
       "4                                0.768841   \n",
       "0                                0.580978   \n",
       "1                                0.580978   \n",
       "2                                0.580978   \n",
       "3                                0.580978   \n",
       "4                                0.580978   \n",
       "0                                0.652899   \n",
       "1                                0.721377   \n",
       "2                                0.775543   \n",
       "3                                0.734601   \n",
       "4                                0.769746   \n",
       "0                                0.547826   \n",
       "1                                0.547826   \n",
       "2                                0.547826   \n",
       "3                                0.547826   \n",
       "4                                0.547826   \n",
       "0                                0.732428   \n",
       "1                                0.705797   \n",
       "2                                0.665580   \n",
       "3                                0.770109   \n",
       "4                                0.719203   \n",
       "0                                0.800725   \n",
       "1                                0.810507   \n",
       "2                                0.807609   \n",
       "3                                0.810507   \n",
       "4                                0.808514   \n",
       "\n",
       "   bace_classification_test_average_precision_score  \\\n",
       "0                                          0.862725   \n",
       "1                                          0.814909   \n",
       "2                                          0.818526   \n",
       "3                                          0.868508   \n",
       "4                                          0.829362   \n",
       "0                                          0.687419   \n",
       "1                                          0.687419   \n",
       "2                                          0.687419   \n",
       "3                                          0.687419   \n",
       "4                                          0.687419   \n",
       "0                                          0.747142   \n",
       "1                                          0.787215   \n",
       "2                                          0.822413   \n",
       "3                                          0.794156   \n",
       "4                                          0.824203   \n",
       "0                                          0.633643   \n",
       "1                                          0.633643   \n",
       "2                                          0.633643   \n",
       "3                                          0.633643   \n",
       "4                                          0.633643   \n",
       "0                                          0.777886   \n",
       "1                                          0.775385   \n",
       "2                                          0.750406   \n",
       "3                                          0.812954   \n",
       "4                                          0.780523   \n",
       "0                                          0.836683   \n",
       "1                                          0.842201   \n",
       "2                                          0.839962   \n",
       "3                                          0.842051   \n",
       "4                                          0.840243   \n",
       "\n",
       "   bace_regression_valid_pearsonr  bace_regression_valid_rmse  \\\n",
       "0                       -0.230438                    0.596198   \n",
       "1                       -0.229989                    0.595898   \n",
       "2                       -0.230389                    0.596087   \n",
       "3                       -0.230280                    0.595910   \n",
       "4                       -0.230689                    0.596143   \n",
       "0                        0.268872                    0.567899   \n",
       "1                        0.343638                    0.559259   \n",
       "2                        0.353859                    0.561093   \n",
       "3                        0.319156                    0.566845   \n",
       "4                        0.313719                    0.568147   \n",
       "0                        0.010729                    0.581904   \n",
       "1                        0.010597                    0.581772   \n",
       "2                        0.010474                    0.581798   \n",
       "3                        0.010353                    0.581820   \n",
       "4                        0.010661                    0.581709   \n",
       "0                        0.166033                    0.555100   \n",
       "1                        0.201710                    0.549131   \n",
       "2                        0.172848                    0.546964   \n",
       "3                        0.170554                    0.552603   \n",
       "4                        0.181692                    0.554777   \n",
       "0                       -0.003584                    0.592910   \n",
       "1                       -0.003292                    0.592905   \n",
       "2                       -0.002621                    0.593019   \n",
       "3                       -0.003633                    0.593103   \n",
       "4                       -0.002773                    0.592951   \n",
       "0                        0.181056                    0.536392   \n",
       "1                        0.178669                    0.538551   \n",
       "2                        0.175059                    0.544611   \n",
       "3                        0.175182                    0.539764   \n",
       "4                        0.185213                    0.536827   \n",
       "\n",
       "   bace_regression_test_pearsonr  bace_regression_test_rmse  \\\n",
       "0                      -0.217982                   1.276962   \n",
       "1                      -0.216031                   1.276871   \n",
       "2                      -0.219816                   1.276949   \n",
       "3                      -0.218276                   1.276893   \n",
       "4                      -0.219356                   1.276957   \n",
       "0                       0.653381                   1.199541   \n",
       "1                       0.672247                   1.170662   \n",
       "2                       0.675618                   1.165820   \n",
       "3                       0.683307                   1.181743   \n",
       "4                       0.665972                   1.191766   \n",
       "0                       0.191228                   1.252637   \n",
       "1                       0.191372                   1.252585   \n",
       "2                       0.191324                   1.252603   \n",
       "3                       0.191308                   1.252617   \n",
       "4                       0.191345                   1.252582   \n",
       "0                       0.517352                   1.179242   \n",
       "1                       0.533566                   1.149470   \n",
       "2                       0.514231                   1.190567   \n",
       "3                       0.542227                   1.164638   \n",
       "4                       0.509093                   1.186495   \n",
       "0                       0.034643                   1.274042   \n",
       "1                       0.034240                   1.274052   \n",
       "2                       0.033375                   1.274098   \n",
       "3                       0.034745                   1.274085   \n",
       "4                       0.033617                   1.274074   \n",
       "0                       0.741226                   1.068135   \n",
       "1                       0.725300                   1.119912   \n",
       "2                       0.715257                   1.144432   \n",
       "3                       0.727938                   1.126450   \n",
       "4                       0.738607                   1.089087   \n",
       "\n",
       "   bbbp_valid_roc_auc_score  bbbp_valid_average_precision_score  ...  \\\n",
       "0                  0.558036                            0.639609  ...   \n",
       "1                  0.557793                            0.639575  ...   \n",
       "2                  0.557939                            0.639505  ...   \n",
       "3                  0.557648                            0.639309  ...   \n",
       "4                  0.558036                            0.639608  ...   \n",
       "0                  0.591421                            0.696895  ...   \n",
       "1                  0.593071                            0.690113  ...   \n",
       "2                  0.589383                            0.691106  ...   \n",
       "3                  0.597826                            0.695128  ...   \n",
       "4                  0.593168                            0.688426  ...   \n",
       "0                  0.952640                            0.955222  ...   \n",
       "1                  0.952252                            0.952802  ...   \n",
       "2                  0.951766                            0.954098  ...   \n",
       "3                  0.954387                            0.956743  ...   \n",
       "4                  0.953610                            0.955316  ...   \n",
       "0                  0.404697                            0.530489  ...   \n",
       "1                  0.404600                            0.530453  ...   \n",
       "2                  0.404600                            0.530453  ...   \n",
       "3                  0.404600                            0.530453  ...   \n",
       "4                  0.404697                            0.530489  ...   \n",
       "0                  0.266984                            0.409481  ...   \n",
       "1                  0.267178                            0.409545  ...   \n",
       "2                  0.266984                            0.409483  ...   \n",
       "3                  0.267275                            0.409589  ...   \n",
       "4                  0.267275                            0.409577  ...   \n",
       "0                  0.969915                            0.966442  ...   \n",
       "1                  0.969915                            0.964857  ...   \n",
       "2                  0.970303                            0.966205  ...   \n",
       "3                  0.969235                            0.963910  ...   \n",
       "4                  0.968847                            0.963658  ...   \n",
       "\n",
       "   delaney_test_rmse  lipo_valid_pearsonr  lipo_valid_rmse  \\\n",
       "0           0.602184             0.576544         0.823305   \n",
       "1           0.538507             0.590941         0.813351   \n",
       "2           0.541780             0.602478         0.807255   \n",
       "3           0.568094             0.556328         0.835626   \n",
       "4           0.519180             0.569293         0.827344   \n",
       "0           0.720130             0.660857         0.759722   \n",
       "1           0.721768             0.670714         0.746713   \n",
       "2           0.712005             0.697282         0.730289   \n",
       "3           0.729394             0.675801         0.747815   \n",
       "4           0.723447             0.654816         0.768090   \n",
       "0           0.566598             0.695097         0.750743   \n",
       "1           0.537460             0.723588         0.727463   \n",
       "2           0.544972             0.712785         0.730614   \n",
       "3           0.544419             0.711281         0.742473   \n",
       "4           0.558833             0.718250         0.724182   \n",
       "0           0.627140             0.580184         0.827611   \n",
       "1           0.626971             0.568434         0.832074   \n",
       "2           0.633649             0.572446         0.827933   \n",
       "3           0.623227             0.584919         0.828532   \n",
       "4           0.646044             0.582805         0.823751   \n",
       "0           0.509745             0.645184         0.769643   \n",
       "1           0.469569             0.599654         0.806719   \n",
       "2           0.512288             0.609248         0.797949   \n",
       "3           0.484284             0.586889         0.815365   \n",
       "4           0.541653             0.604970         0.804004   \n",
       "0           0.441218             0.744444         0.705519   \n",
       "1           0.435431             0.740711         0.735474   \n",
       "2           0.436801             0.749266         0.700821   \n",
       "3           0.435814             0.744456         0.712699   \n",
       "4           0.448837             0.720865         0.734076   \n",
       "\n",
       "   lipo_test_pearsonr  lipo_test_rmse  tox21_valid_roc_auc_score  \\\n",
       "0            0.512566        0.806596                   0.762783   \n",
       "1            0.524219        0.790027                   0.761239   \n",
       "2            0.505320        0.812510                   0.734858   \n",
       "3            0.447331        0.826765                   0.762268   \n",
       "4            0.491301        0.799713                   0.785904   \n",
       "0            0.582182        0.750324                   0.735308   \n",
       "1            0.624257        0.717793                   0.730268   \n",
       "2            0.663698        0.696253                   0.709463   \n",
       "3            0.633899        0.718338                   0.700969   \n",
       "4            0.565669        0.759907                   0.722268   \n",
       "0            0.680795        0.696812                   0.770290   \n",
       "1            0.713709        0.677001                   0.769775   \n",
       "2            0.702685        0.676545                   0.772049   \n",
       "3            0.701187        0.683299                   0.766730   \n",
       "4            0.706217        0.674961                   0.771577   \n",
       "0            0.510875        0.805915                   0.739662   \n",
       "1            0.503531        0.806500                   0.741421   \n",
       "2            0.470739        0.836043                   0.738418   \n",
       "3            0.528177        0.788722                   0.740520   \n",
       "4            0.529007        0.794890                   0.716970   \n",
       "0            0.531337        0.782116                   0.782730   \n",
       "1            0.514140        0.788926                   0.761625   \n",
       "2            0.509164        0.795617                   0.769647   \n",
       "3            0.503509        0.800754                   0.776381   \n",
       "4            0.507554        0.796507                   0.780156   \n",
       "0            0.722884        0.665679                   0.783717   \n",
       "1            0.717953        0.696740                   0.786676   \n",
       "2            0.733807        0.657533                   0.777239   \n",
       "3            0.712487        0.683005                   0.755920   \n",
       "4            0.692787        0.692444                   0.780285   \n",
       "\n",
       "   tox21_valid_average_precision_score  tox21_test_roc_auc_score  \\\n",
       "0                             0.412171                  0.729537   \n",
       "1                             0.368507                  0.741719   \n",
       "2                             0.433442                  0.745780   \n",
       "3                             0.433016                  0.737609   \n",
       "4                             0.453306                  0.746074   \n",
       "0                             0.404245                  0.730173   \n",
       "1                             0.414122                  0.712804   \n",
       "2                             0.432810                  0.715593   \n",
       "3                             0.360835                  0.724546   \n",
       "4                             0.380278                  0.722491   \n",
       "0                             0.429965                  0.752287   \n",
       "1                             0.427343                  0.752777   \n",
       "2                             0.429428                  0.755908   \n",
       "3                             0.428032                  0.750330   \n",
       "4                             0.429924                  0.750917   \n",
       "0                             0.390483                  0.761975   \n",
       "1                             0.419757                  0.753804   \n",
       "2                             0.435662                  0.750183   \n",
       "3                             0.381594                  0.766574   \n",
       "4                             0.382302                  0.736093   \n",
       "0                             0.409358                  0.724644   \n",
       "1                             0.408209                  0.771858   \n",
       "2                             0.426420                  0.751504   \n",
       "3                             0.431358                  0.738343   \n",
       "4                             0.400269                  0.740154   \n",
       "0                             0.472981                  0.740594   \n",
       "1                             0.469447                  0.732325   \n",
       "2                             0.451759                  0.745389   \n",
       "3                             0.419479                  0.734185   \n",
       "4                             0.474502                  0.748031   \n",
       "\n",
       "   tox21_test_average_precision_score  run_name  \n",
       "0                            0.286098    run_11  \n",
       "1                            0.285398    run_11  \n",
       "2                            0.299844    run_11  \n",
       "3                            0.343815    run_11  \n",
       "4                            0.306306    run_11  \n",
       "0                            0.378770    run_19  \n",
       "1                            0.345822    run_19  \n",
       "2                            0.341018    run_19  \n",
       "3                            0.379368    run_19  \n",
       "4                            0.316989    run_19  \n",
       "0                            0.392007    run_34  \n",
       "1                            0.402069    run_34  \n",
       "2                            0.393549    run_34  \n",
       "3                            0.381192    run_34  \n",
       "4                            0.390249    run_34  \n",
       "0                            0.334774    run_38  \n",
       "1                            0.325718    run_38  \n",
       "2                            0.348128    run_38  \n",
       "3                            0.373289    run_38  \n",
       "4                            0.346758    run_38  \n",
       "0                            0.319663    run_39  \n",
       "1                            0.277485    run_39  \n",
       "2                            0.299939    run_39  \n",
       "3                            0.287014    run_39  \n",
       "4                            0.308734    run_39  \n",
       "0                            0.352845    run_45  \n",
       "1                            0.357853    run_45  \n",
       "2                            0.366156    run_45  \n",
       "3                            0.352519    run_45  \n",
       "4                            0.358638    run_45  \n",
       "\n",
       "[30 rows x 33 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2c3b7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>bace_classification_valid_roc_auc_score_mean</th>\n",
       "      <th>bace_classification_valid_average_precision_score_mean</th>\n",
       "      <th>bace_classification_valid_roc_auc_score_std</th>\n",
       "      <th>bace_classification_valid_average_precision_score_std</th>\n",
       "      <th>bace_classification_test_roc_auc_score_mean</th>\n",
       "      <th>bace_classification_test_average_precision_score_mean</th>\n",
       "      <th>bace_classification_test_roc_auc_score_std</th>\n",
       "      <th>bace_classification_test_average_precision_score_std</th>\n",
       "      <th>bace_regression_valid_pearsonr_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>lipo_test_pearsonr_std</th>\n",
       "      <th>lipo_test_rmse_std</th>\n",
       "      <th>tox21_valid_roc_auc_score_mean</th>\n",
       "      <th>tox21_valid_average_precision_score_mean</th>\n",
       "      <th>tox21_valid_roc_auc_score_std</th>\n",
       "      <th>tox21_valid_average_precision_score_std</th>\n",
       "      <th>tox21_test_roc_auc_score_mean</th>\n",
       "      <th>tox21_test_average_precision_score_mean</th>\n",
       "      <th>tox21_test_roc_auc_score_std</th>\n",
       "      <th>tox21_test_average_precision_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.626155</td>\n",
       "      <td>0.679389</td>\n",
       "      <td>0.009590</td>\n",
       "      <td>0.023753</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.838806</td>\n",
       "      <td>1.642747e-02</td>\n",
       "      <td>2.247588e-02</td>\n",
       "      <td>-0.230357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026639</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.761410</td>\n",
       "      <td>0.420089</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>0.740144</td>\n",
       "      <td>0.304292</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.021326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.520682</td>\n",
       "      <td>0.591395</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.580978</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.319849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035551</td>\n",
       "      <td>0.023326</td>\n",
       "      <td>0.719655</td>\n",
       "      <td>0.398458</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>0.721121</td>\n",
       "      <td>0.352393</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.023872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_34</td>\n",
       "      <td>0.685856</td>\n",
       "      <td>0.684942</td>\n",
       "      <td>0.020912</td>\n",
       "      <td>0.016583</td>\n",
       "      <td>0.730833</td>\n",
       "      <td>0.795026</td>\n",
       "      <td>4.402426e-02</td>\n",
       "      <td>2.812800e-02</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>0.770084</td>\n",
       "      <td>0.428939</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.752444</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.006686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.471891</td>\n",
       "      <td>0.567802</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.633643</td>\n",
       "      <td>4.965068e-17</td>\n",
       "      <td>4.965068e-17</td>\n",
       "      <td>0.178568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.735398</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.753726</td>\n",
       "      <td>0.345733</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>0.016043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.689126</td>\n",
       "      <td>0.697289</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.718623</td>\n",
       "      <td>0.779431</td>\n",
       "      <td>3.411678e-02</td>\n",
       "      <td>1.993097e-02</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.774108</td>\n",
       "      <td>0.415123</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.745301</td>\n",
       "      <td>0.298567</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>0.015021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.639943</td>\n",
       "      <td>0.683314</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.807572</td>\n",
       "      <td>0.840228</td>\n",
       "      <td>3.605755e-03</td>\n",
       "      <td>1.992883e-03</td>\n",
       "      <td>0.179036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>0.776767</td>\n",
       "      <td>0.457633</td>\n",
       "      <td>0.010897</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>0.740105</td>\n",
       "      <td>0.357602</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>0.004955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  run_name  bace_classification_valid_roc_auc_score_mean  \\\n",
       "0   run_11                                      0.626155   \n",
       "1   run_19                                      0.520682   \n",
       "2   run_34                                      0.685856   \n",
       "3   run_38                                      0.471891   \n",
       "4   run_39                                      0.689126   \n",
       "5   run_45                                      0.639943   \n",
       "\n",
       "   bace_classification_valid_average_precision_score_mean  \\\n",
       "0                                           0.679389        \n",
       "1                                           0.591395        \n",
       "2                                           0.684942        \n",
       "3                                           0.567802        \n",
       "4                                           0.697289        \n",
       "5                                           0.683314        \n",
       "\n",
       "   bace_classification_valid_roc_auc_score_std  \\\n",
       "0                                     0.009590   \n",
       "1                                     0.000087   \n",
       "2                                     0.020912   \n",
       "3                                     0.000071   \n",
       "4                                     0.003346   \n",
       "5                                     0.003346   \n",
       "\n",
       "   bace_classification_valid_average_precision_score_std  \\\n",
       "0                                           0.023753       \n",
       "1                                           0.000791       \n",
       "2                                           0.016583       \n",
       "3                                           0.000020       \n",
       "4                                           0.004038       \n",
       "5                                           0.002691       \n",
       "\n",
       "   bace_classification_test_roc_auc_score_mean  \\\n",
       "0                                     0.782609   \n",
       "1                                     0.580978   \n",
       "2                                     0.730833   \n",
       "3                                     0.547826   \n",
       "4                                     0.718623   \n",
       "5                                     0.807572   \n",
       "\n",
       "   bace_classification_test_average_precision_score_mean  \\\n",
       "0                                           0.838806       \n",
       "1                                           0.687419       \n",
       "2                                           0.795026       \n",
       "3                                           0.633643       \n",
       "4                                           0.779431       \n",
       "5                                           0.840228       \n",
       "\n",
       "   bace_classification_test_roc_auc_score_std  \\\n",
       "0                                1.642747e-02   \n",
       "1                                0.000000e+00   \n",
       "2                                4.402426e-02   \n",
       "3                                4.965068e-17   \n",
       "4                                3.411678e-02   \n",
       "5                                3.605755e-03   \n",
       "\n",
       "   bace_classification_test_average_precision_score_std  \\\n",
       "0                                       2.247588e-02      \n",
       "1                                       0.000000e+00      \n",
       "2                                       2.812800e-02      \n",
       "3                                       4.965068e-17      \n",
       "4                                       1.993097e-02      \n",
       "5                                       1.992883e-03      \n",
       "\n",
       "   bace_regression_valid_pearsonr_mean  ...  lipo_test_pearsonr_std  \\\n",
       "0                            -0.230357  ...                0.026639   \n",
       "1                             0.319849  ...                0.035551   \n",
       "2                             0.010563  ...                0.010953   \n",
       "3                             0.178568  ...                0.021279   \n",
       "4                            -0.003180  ...                0.009715   \n",
       "5                             0.179036  ...                0.013561   \n",
       "\n",
       "   lipo_test_rmse_std  tox21_valid_roc_auc_score_mean  \\\n",
       "0            0.012347                        0.761410   \n",
       "1            0.023326                        0.719655   \n",
       "2            0.008062                        0.770084   \n",
       "3            0.016272                        0.735398   \n",
       "4            0.006544                        0.774108   \n",
       "5            0.015164                        0.776767   \n",
       "\n",
       "   tox21_valid_average_precision_score_mean  tox21_valid_roc_auc_score_std  \\\n",
       "0                                  0.420089                       0.016172   \n",
       "1                                  0.398458                       0.012787   \n",
       "2                                  0.428939                       0.001870   \n",
       "3                                  0.401960                       0.009267   \n",
       "4                                  0.415123                       0.007640   \n",
       "5                                  0.457633                       0.010897   \n",
       "\n",
       "   tox21_valid_average_precision_score_std  tox21_test_roc_auc_score_mean  \\\n",
       "0                                 0.028887                       0.740144   \n",
       "1                                 0.025318                       0.721121   \n",
       "2                                 0.001061                       0.752444   \n",
       "3                                 0.021842                       0.753726   \n",
       "4                                 0.011772                       0.745301   \n",
       "5                                 0.020736                       0.740105   \n",
       "\n",
       "   tox21_test_average_precision_score_mean  tox21_test_roc_auc_score_std  \\\n",
       "0                                 0.304292                      0.006138   \n",
       "1                                 0.352393                      0.006249   \n",
       "2                                 0.391813                      0.001946   \n",
       "3                                 0.345733                      0.010551   \n",
       "4                                 0.298567                      0.015782   \n",
       "5                                 0.357602                      0.006108   \n",
       "\n",
       "   tox21_test_average_precision_score_std  \n",
       "0                                0.021326  \n",
       "1                                0.023872  \n",
       "2                                0.006686  \n",
       "3                                0.016043  \n",
       "4                                0.015021  \n",
       "5                                0.004955  \n",
       "\n",
       "[6 rows x 65 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf0bffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_avg_df = pd.merge(left=df, right=df_avg, on='run_name')\n",
    "# combined_avg_df['run_name'] = combined_avg_df['run_name'].apply(lambda x: f\"mlm_{x}\")\n",
    "\n",
    "combined_all_df = pd.merge(left=df, right=df_all, on='run_name')\n",
    "# combined_all_df['run_name'] = combined_all_df['run_name'].apply(lambda x: f\"mlm_{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0bda290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>min_eval_loss</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>attention_probs_dropout_prob</th>\n",
       "      <th>hidden_dropout_prob</th>\n",
       "      <th>intermediate_size</th>\n",
       "      <th>num_attention_heads</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>pretraining_task</th>\n",
       "      <th>...</th>\n",
       "      <th>lipo_test_pearsonr_std</th>\n",
       "      <th>lipo_test_rmse_std</th>\n",
       "      <th>tox21_valid_roc_auc_score_mean</th>\n",
       "      <th>tox21_valid_average_precision_score_mean</th>\n",
       "      <th>tox21_valid_roc_auc_score_std</th>\n",
       "      <th>tox21_valid_average_precision_score_std</th>\n",
       "      <th>tox21_test_roc_auc_score_mean</th>\n",
       "      <th>tox21_test_average_precision_score_mean</th>\n",
       "      <th>tox21_test_roc_auc_score_std</th>\n",
       "      <th>tox21_test_average_precision_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.774108</td>\n",
       "      <td>0.415123</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.745301</td>\n",
       "      <td>0.298567</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>0.015021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.615919</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026639</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.761410</td>\n",
       "      <td>0.420089</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>0.740144</td>\n",
       "      <td>0.304292</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.021326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_34</td>\n",
       "      <td>0.131611</td>\n",
       "      <td>696</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.226</td>\n",
       "      <td>8436</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>0.770084</td>\n",
       "      <td>0.428939</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.752444</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.006686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.457947</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.735398</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.753726</td>\n",
       "      <td>0.345733</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>0.016043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>0.776767</td>\n",
       "      <td>0.457633</td>\n",
       "      <td>0.010897</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>0.740105</td>\n",
       "      <td>0.357602</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>0.004955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035551</td>\n",
       "      <td>0.023326</td>\n",
       "      <td>0.719655</td>\n",
       "      <td>0.398458</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>0.721121</td>\n",
       "      <td>0.352393</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.023872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  run_name  min_eval_loss  hidden_size  attention_probs_dropout_prob  \\\n",
       "0   run_39       0.429169          209                         0.176   \n",
       "1   run_11       0.615919          112                         0.118   \n",
       "2   run_34       0.131611          696                         0.148   \n",
       "3   run_38       0.457947          126                         0.109   \n",
       "4   run_45       0.147017          384                         0.109   \n",
       "5   run_19       0.196440           57                         0.129   \n",
       "\n",
       "   hidden_dropout_prob  intermediate_size  num_attention_heads  \\\n",
       "0                0.128               3968                   11   \n",
       "1                0.183               4844                    8   \n",
       "2                0.226               8436                   12   \n",
       "3                0.279                456                    3   \n",
       "4                0.144                464                   12   \n",
       "5                0.139              10476                    3   \n",
       "\n",
       "   num_hidden_layers  learning_rate pretraining_task  ...  \\\n",
       "0                  3       0.000002          10M-MLM  ...   \n",
       "1                  5       0.000002          10M-MLM  ...   \n",
       "2                  2       0.000087          10M-MLM  ...   \n",
       "3                  2       0.000021          10M-MLM  ...   \n",
       "4                  3       0.000141          10M-MLM  ...   \n",
       "5                  5       0.000058          10M-MLM  ...   \n",
       "\n",
       "   lipo_test_pearsonr_std  lipo_test_rmse_std  tox21_valid_roc_auc_score_mean  \\\n",
       "0                0.009715            0.006544                        0.774108   \n",
       "1                0.026639            0.012347                        0.761410   \n",
       "2                0.010953            0.008062                        0.770084   \n",
       "3                0.021279            0.016272                        0.735398   \n",
       "4                0.013561            0.015164                        0.776767   \n",
       "5                0.035551            0.023326                        0.719655   \n",
       "\n",
       "   tox21_valid_average_precision_score_mean  tox21_valid_roc_auc_score_std  \\\n",
       "0                                  0.415123                       0.007640   \n",
       "1                                  0.420089                       0.016172   \n",
       "2                                  0.428939                       0.001870   \n",
       "3                                  0.401960                       0.009267   \n",
       "4                                  0.457633                       0.010897   \n",
       "5                                  0.398458                       0.012787   \n",
       "\n",
       "   tox21_valid_average_precision_score_std  tox21_test_roc_auc_score_mean  \\\n",
       "0                                 0.011772                       0.745301   \n",
       "1                                 0.028887                       0.740144   \n",
       "2                                 0.001061                       0.752444   \n",
       "3                                 0.021842                       0.753726   \n",
       "4                                 0.020736                       0.740105   \n",
       "5                                 0.025318                       0.721121   \n",
       "\n",
       "   tox21_test_average_precision_score_mean  tox21_test_roc_auc_score_std  \\\n",
       "0                                 0.298567                      0.015782   \n",
       "1                                 0.304292                      0.006138   \n",
       "2                                 0.391813                      0.001946   \n",
       "3                                 0.345733                      0.010551   \n",
       "4                                 0.357602                      0.006108   \n",
       "5                                 0.352393                      0.006249   \n",
       "\n",
       "   tox21_test_average_precision_score_std  \n",
       "0                                0.015021  \n",
       "1                                0.021326  \n",
       "2                                0.006686  \n",
       "3                                0.016043  \n",
       "4                                0.004955  \n",
       "5                                0.023872  \n",
       "\n",
       "[6 rows x 74 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a4a5531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>min_eval_loss</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>attention_probs_dropout_prob</th>\n",
       "      <th>hidden_dropout_prob</th>\n",
       "      <th>intermediate_size</th>\n",
       "      <th>num_attention_heads</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>pretraining_task</th>\n",
       "      <th>...</th>\n",
       "      <th>delaney_test_pearsonr</th>\n",
       "      <th>delaney_test_rmse</th>\n",
       "      <th>lipo_valid_pearsonr</th>\n",
       "      <th>lipo_valid_rmse</th>\n",
       "      <th>lipo_test_pearsonr</th>\n",
       "      <th>lipo_test_rmse</th>\n",
       "      <th>tox21_valid_roc_auc_score</th>\n",
       "      <th>tox21_valid_average_precision_score</th>\n",
       "      <th>tox21_test_roc_auc_score</th>\n",
       "      <th>tox21_test_average_precision_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871144</td>\n",
       "      <td>0.509745</td>\n",
       "      <td>0.645184</td>\n",
       "      <td>0.769643</td>\n",
       "      <td>0.531337</td>\n",
       "      <td>0.782116</td>\n",
       "      <td>0.782730</td>\n",
       "      <td>0.409358</td>\n",
       "      <td>0.724644</td>\n",
       "      <td>0.319663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893529</td>\n",
       "      <td>0.469569</td>\n",
       "      <td>0.599654</td>\n",
       "      <td>0.806719</td>\n",
       "      <td>0.514140</td>\n",
       "      <td>0.788926</td>\n",
       "      <td>0.761625</td>\n",
       "      <td>0.408209</td>\n",
       "      <td>0.771858</td>\n",
       "      <td>0.277485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875403</td>\n",
       "      <td>0.512288</td>\n",
       "      <td>0.609248</td>\n",
       "      <td>0.797949</td>\n",
       "      <td>0.509164</td>\n",
       "      <td>0.795617</td>\n",
       "      <td>0.769647</td>\n",
       "      <td>0.426420</td>\n",
       "      <td>0.751504</td>\n",
       "      <td>0.299939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888880</td>\n",
       "      <td>0.484284</td>\n",
       "      <td>0.586889</td>\n",
       "      <td>0.815365</td>\n",
       "      <td>0.503509</td>\n",
       "      <td>0.800754</td>\n",
       "      <td>0.776381</td>\n",
       "      <td>0.431358</td>\n",
       "      <td>0.738343</td>\n",
       "      <td>0.287014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.541653</td>\n",
       "      <td>0.604970</td>\n",
       "      <td>0.804004</td>\n",
       "      <td>0.507554</td>\n",
       "      <td>0.796507</td>\n",
       "      <td>0.780156</td>\n",
       "      <td>0.400269</td>\n",
       "      <td>0.740154</td>\n",
       "      <td>0.308734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.615919</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812892</td>\n",
       "      <td>0.602184</td>\n",
       "      <td>0.576544</td>\n",
       "      <td>0.823305</td>\n",
       "      <td>0.512566</td>\n",
       "      <td>0.806596</td>\n",
       "      <td>0.762783</td>\n",
       "      <td>0.412171</td>\n",
       "      <td>0.729537</td>\n",
       "      <td>0.286098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.615919</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860755</td>\n",
       "      <td>0.538507</td>\n",
       "      <td>0.590941</td>\n",
       "      <td>0.813351</td>\n",
       "      <td>0.524219</td>\n",
       "      <td>0.790027</td>\n",
       "      <td>0.761239</td>\n",
       "      <td>0.368507</td>\n",
       "      <td>0.741719</td>\n",
       "      <td>0.285398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.615919</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852103</td>\n",
       "      <td>0.541780</td>\n",
       "      <td>0.602478</td>\n",
       "      <td>0.807255</td>\n",
       "      <td>0.505320</td>\n",
       "      <td>0.812510</td>\n",
       "      <td>0.734858</td>\n",
       "      <td>0.433442</td>\n",
       "      <td>0.745780</td>\n",
       "      <td>0.299844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.615919</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833494</td>\n",
       "      <td>0.568094</td>\n",
       "      <td>0.556328</td>\n",
       "      <td>0.835626</td>\n",
       "      <td>0.447331</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.762268</td>\n",
       "      <td>0.433016</td>\n",
       "      <td>0.737609</td>\n",
       "      <td>0.343815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.615919</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863538</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>0.569293</td>\n",
       "      <td>0.827344</td>\n",
       "      <td>0.491301</td>\n",
       "      <td>0.799713</td>\n",
       "      <td>0.785904</td>\n",
       "      <td>0.453306</td>\n",
       "      <td>0.746074</td>\n",
       "      <td>0.306306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>run_34</td>\n",
       "      <td>0.131611</td>\n",
       "      <td>696</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.226</td>\n",
       "      <td>8436</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844882</td>\n",
       "      <td>0.566598</td>\n",
       "      <td>0.695097</td>\n",
       "      <td>0.750743</td>\n",
       "      <td>0.680795</td>\n",
       "      <td>0.696812</td>\n",
       "      <td>0.770290</td>\n",
       "      <td>0.429965</td>\n",
       "      <td>0.752287</td>\n",
       "      <td>0.392007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>run_34</td>\n",
       "      <td>0.131611</td>\n",
       "      <td>696</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.226</td>\n",
       "      <td>8436</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865144</td>\n",
       "      <td>0.537460</td>\n",
       "      <td>0.723588</td>\n",
       "      <td>0.727463</td>\n",
       "      <td>0.713709</td>\n",
       "      <td>0.677001</td>\n",
       "      <td>0.769775</td>\n",
       "      <td>0.427343</td>\n",
       "      <td>0.752777</td>\n",
       "      <td>0.402069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>run_34</td>\n",
       "      <td>0.131611</td>\n",
       "      <td>696</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.226</td>\n",
       "      <td>8436</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857924</td>\n",
       "      <td>0.544972</td>\n",
       "      <td>0.712785</td>\n",
       "      <td>0.730614</td>\n",
       "      <td>0.702685</td>\n",
       "      <td>0.676545</td>\n",
       "      <td>0.772049</td>\n",
       "      <td>0.429428</td>\n",
       "      <td>0.755908</td>\n",
       "      <td>0.393549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>run_34</td>\n",
       "      <td>0.131611</td>\n",
       "      <td>696</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.226</td>\n",
       "      <td>8436</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858429</td>\n",
       "      <td>0.544419</td>\n",
       "      <td>0.711281</td>\n",
       "      <td>0.742473</td>\n",
       "      <td>0.701187</td>\n",
       "      <td>0.683299</td>\n",
       "      <td>0.766730</td>\n",
       "      <td>0.428032</td>\n",
       "      <td>0.750330</td>\n",
       "      <td>0.381192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>run_34</td>\n",
       "      <td>0.131611</td>\n",
       "      <td>696</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.226</td>\n",
       "      <td>8436</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842092</td>\n",
       "      <td>0.558833</td>\n",
       "      <td>0.718250</td>\n",
       "      <td>0.724182</td>\n",
       "      <td>0.706217</td>\n",
       "      <td>0.674961</td>\n",
       "      <td>0.771577</td>\n",
       "      <td>0.429924</td>\n",
       "      <td>0.750917</td>\n",
       "      <td>0.390249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.457947</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797885</td>\n",
       "      <td>0.627140</td>\n",
       "      <td>0.580184</td>\n",
       "      <td>0.827611</td>\n",
       "      <td>0.510875</td>\n",
       "      <td>0.805915</td>\n",
       "      <td>0.739662</td>\n",
       "      <td>0.390483</td>\n",
       "      <td>0.761975</td>\n",
       "      <td>0.334774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.457947</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799174</td>\n",
       "      <td>0.626971</td>\n",
       "      <td>0.568434</td>\n",
       "      <td>0.832074</td>\n",
       "      <td>0.503531</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>0.741421</td>\n",
       "      <td>0.419757</td>\n",
       "      <td>0.753804</td>\n",
       "      <td>0.325718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.457947</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793191</td>\n",
       "      <td>0.633649</td>\n",
       "      <td>0.572446</td>\n",
       "      <td>0.827933</td>\n",
       "      <td>0.470739</td>\n",
       "      <td>0.836043</td>\n",
       "      <td>0.738418</td>\n",
       "      <td>0.435662</td>\n",
       "      <td>0.750183</td>\n",
       "      <td>0.348128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.457947</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800279</td>\n",
       "      <td>0.623227</td>\n",
       "      <td>0.584919</td>\n",
       "      <td>0.828532</td>\n",
       "      <td>0.528177</td>\n",
       "      <td>0.788722</td>\n",
       "      <td>0.740520</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.766574</td>\n",
       "      <td>0.373289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.457947</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785220</td>\n",
       "      <td>0.646044</td>\n",
       "      <td>0.582805</td>\n",
       "      <td>0.823751</td>\n",
       "      <td>0.529007</td>\n",
       "      <td>0.794890</td>\n",
       "      <td>0.716970</td>\n",
       "      <td>0.382302</td>\n",
       "      <td>0.736093</td>\n",
       "      <td>0.346758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905881</td>\n",
       "      <td>0.441218</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.705519</td>\n",
       "      <td>0.722884</td>\n",
       "      <td>0.665679</td>\n",
       "      <td>0.783717</td>\n",
       "      <td>0.472981</td>\n",
       "      <td>0.740594</td>\n",
       "      <td>0.352845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909580</td>\n",
       "      <td>0.435431</td>\n",
       "      <td>0.740711</td>\n",
       "      <td>0.735474</td>\n",
       "      <td>0.717953</td>\n",
       "      <td>0.696740</td>\n",
       "      <td>0.786676</td>\n",
       "      <td>0.469447</td>\n",
       "      <td>0.732325</td>\n",
       "      <td>0.357853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908232</td>\n",
       "      <td>0.436801</td>\n",
       "      <td>0.749266</td>\n",
       "      <td>0.700821</td>\n",
       "      <td>0.733807</td>\n",
       "      <td>0.657533</td>\n",
       "      <td>0.777239</td>\n",
       "      <td>0.451759</td>\n",
       "      <td>0.745389</td>\n",
       "      <td>0.366156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909832</td>\n",
       "      <td>0.435814</td>\n",
       "      <td>0.744456</td>\n",
       "      <td>0.712699</td>\n",
       "      <td>0.712487</td>\n",
       "      <td>0.683005</td>\n",
       "      <td>0.755920</td>\n",
       "      <td>0.419479</td>\n",
       "      <td>0.734185</td>\n",
       "      <td>0.352519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901861</td>\n",
       "      <td>0.448837</td>\n",
       "      <td>0.720865</td>\n",
       "      <td>0.734076</td>\n",
       "      <td>0.692787</td>\n",
       "      <td>0.692444</td>\n",
       "      <td>0.780285</td>\n",
       "      <td>0.474502</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.358638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777678</td>\n",
       "      <td>0.720130</td>\n",
       "      <td>0.660857</td>\n",
       "      <td>0.759722</td>\n",
       "      <td>0.582182</td>\n",
       "      <td>0.750324</td>\n",
       "      <td>0.735308</td>\n",
       "      <td>0.404245</td>\n",
       "      <td>0.730173</td>\n",
       "      <td>0.378770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779711</td>\n",
       "      <td>0.721768</td>\n",
       "      <td>0.670714</td>\n",
       "      <td>0.746713</td>\n",
       "      <td>0.624257</td>\n",
       "      <td>0.717793</td>\n",
       "      <td>0.730268</td>\n",
       "      <td>0.414122</td>\n",
       "      <td>0.712804</td>\n",
       "      <td>0.345822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783739</td>\n",
       "      <td>0.712005</td>\n",
       "      <td>0.697282</td>\n",
       "      <td>0.730289</td>\n",
       "      <td>0.663698</td>\n",
       "      <td>0.696253</td>\n",
       "      <td>0.709463</td>\n",
       "      <td>0.432810</td>\n",
       "      <td>0.715593</td>\n",
       "      <td>0.341018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773575</td>\n",
       "      <td>0.729394</td>\n",
       "      <td>0.675801</td>\n",
       "      <td>0.747815</td>\n",
       "      <td>0.633899</td>\n",
       "      <td>0.718338</td>\n",
       "      <td>0.700969</td>\n",
       "      <td>0.360835</td>\n",
       "      <td>0.724546</td>\n",
       "      <td>0.379368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773854</td>\n",
       "      <td>0.723447</td>\n",
       "      <td>0.654816</td>\n",
       "      <td>0.768090</td>\n",
       "      <td>0.565669</td>\n",
       "      <td>0.759907</td>\n",
       "      <td>0.722268</td>\n",
       "      <td>0.380278</td>\n",
       "      <td>0.722491</td>\n",
       "      <td>0.316989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_name  min_eval_loss  hidden_size  attention_probs_dropout_prob  \\\n",
       "0    run_39       0.429169          209                         0.176   \n",
       "1    run_39       0.429169          209                         0.176   \n",
       "2    run_39       0.429169          209                         0.176   \n",
       "3    run_39       0.429169          209                         0.176   \n",
       "4    run_39       0.429169          209                         0.176   \n",
       "5    run_11       0.615919          112                         0.118   \n",
       "6    run_11       0.615919          112                         0.118   \n",
       "7    run_11       0.615919          112                         0.118   \n",
       "8    run_11       0.615919          112                         0.118   \n",
       "9    run_11       0.615919          112                         0.118   \n",
       "10   run_34       0.131611          696                         0.148   \n",
       "11   run_34       0.131611          696                         0.148   \n",
       "12   run_34       0.131611          696                         0.148   \n",
       "13   run_34       0.131611          696                         0.148   \n",
       "14   run_34       0.131611          696                         0.148   \n",
       "15   run_38       0.457947          126                         0.109   \n",
       "16   run_38       0.457947          126                         0.109   \n",
       "17   run_38       0.457947          126                         0.109   \n",
       "18   run_38       0.457947          126                         0.109   \n",
       "19   run_38       0.457947          126                         0.109   \n",
       "20   run_45       0.147017          384                         0.109   \n",
       "21   run_45       0.147017          384                         0.109   \n",
       "22   run_45       0.147017          384                         0.109   \n",
       "23   run_45       0.147017          384                         0.109   \n",
       "24   run_45       0.147017          384                         0.109   \n",
       "25   run_19       0.196440           57                         0.129   \n",
       "26   run_19       0.196440           57                         0.129   \n",
       "27   run_19       0.196440           57                         0.129   \n",
       "28   run_19       0.196440           57                         0.129   \n",
       "29   run_19       0.196440           57                         0.129   \n",
       "\n",
       "    hidden_dropout_prob  intermediate_size  num_attention_heads  \\\n",
       "0                 0.128               3968                   11   \n",
       "1                 0.128               3968                   11   \n",
       "2                 0.128               3968                   11   \n",
       "3                 0.128               3968                   11   \n",
       "4                 0.128               3968                   11   \n",
       "5                 0.183               4844                    8   \n",
       "6                 0.183               4844                    8   \n",
       "7                 0.183               4844                    8   \n",
       "8                 0.183               4844                    8   \n",
       "9                 0.183               4844                    8   \n",
       "10                0.226               8436                   12   \n",
       "11                0.226               8436                   12   \n",
       "12                0.226               8436                   12   \n",
       "13                0.226               8436                   12   \n",
       "14                0.226               8436                   12   \n",
       "15                0.279                456                    3   \n",
       "16                0.279                456                    3   \n",
       "17                0.279                456                    3   \n",
       "18                0.279                456                    3   \n",
       "19                0.279                456                    3   \n",
       "20                0.144                464                   12   \n",
       "21                0.144                464                   12   \n",
       "22                0.144                464                   12   \n",
       "23                0.144                464                   12   \n",
       "24                0.144                464                   12   \n",
       "25                0.139              10476                    3   \n",
       "26                0.139              10476                    3   \n",
       "27                0.139              10476                    3   \n",
       "28                0.139              10476                    3   \n",
       "29                0.139              10476                    3   \n",
       "\n",
       "    num_hidden_layers  learning_rate pretraining_task  ...  \\\n",
       "0                   3       0.000002          10M-MLM  ...   \n",
       "1                   3       0.000002          10M-MLM  ...   \n",
       "2                   3       0.000002          10M-MLM  ...   \n",
       "3                   3       0.000002          10M-MLM  ...   \n",
       "4                   3       0.000002          10M-MLM  ...   \n",
       "5                   5       0.000002          10M-MLM  ...   \n",
       "6                   5       0.000002          10M-MLM  ...   \n",
       "7                   5       0.000002          10M-MLM  ...   \n",
       "8                   5       0.000002          10M-MLM  ...   \n",
       "9                   5       0.000002          10M-MLM  ...   \n",
       "10                  2       0.000087          10M-MLM  ...   \n",
       "11                  2       0.000087          10M-MLM  ...   \n",
       "12                  2       0.000087          10M-MLM  ...   \n",
       "13                  2       0.000087          10M-MLM  ...   \n",
       "14                  2       0.000087          10M-MLM  ...   \n",
       "15                  2       0.000021          10M-MLM  ...   \n",
       "16                  2       0.000021          10M-MLM  ...   \n",
       "17                  2       0.000021          10M-MLM  ...   \n",
       "18                  2       0.000021          10M-MLM  ...   \n",
       "19                  2       0.000021          10M-MLM  ...   \n",
       "20                  3       0.000141          10M-MLM  ...   \n",
       "21                  3       0.000141          10M-MLM  ...   \n",
       "22                  3       0.000141          10M-MLM  ...   \n",
       "23                  3       0.000141          10M-MLM  ...   \n",
       "24                  3       0.000141          10M-MLM  ...   \n",
       "25                  5       0.000058          10M-MLM  ...   \n",
       "26                  5       0.000058          10M-MLM  ...   \n",
       "27                  5       0.000058          10M-MLM  ...   \n",
       "28                  5       0.000058          10M-MLM  ...   \n",
       "29                  5       0.000058          10M-MLM  ...   \n",
       "\n",
       "    delaney_test_pearsonr  delaney_test_rmse  lipo_valid_pearsonr  \\\n",
       "0                0.871144           0.509745             0.645184   \n",
       "1                0.893529           0.469569             0.599654   \n",
       "2                0.875403           0.512288             0.609248   \n",
       "3                0.888880           0.484284             0.586889   \n",
       "4                0.853968           0.541653             0.604970   \n",
       "5                0.812892           0.602184             0.576544   \n",
       "6                0.860755           0.538507             0.590941   \n",
       "7                0.852103           0.541780             0.602478   \n",
       "8                0.833494           0.568094             0.556328   \n",
       "9                0.863538           0.519180             0.569293   \n",
       "10               0.844882           0.566598             0.695097   \n",
       "11               0.865144           0.537460             0.723588   \n",
       "12               0.857924           0.544972             0.712785   \n",
       "13               0.858429           0.544419             0.711281   \n",
       "14               0.842092           0.558833             0.718250   \n",
       "15               0.797885           0.627140             0.580184   \n",
       "16               0.799174           0.626971             0.568434   \n",
       "17               0.793191           0.633649             0.572446   \n",
       "18               0.800279           0.623227             0.584919   \n",
       "19               0.785220           0.646044             0.582805   \n",
       "20               0.905881           0.441218             0.744444   \n",
       "21               0.909580           0.435431             0.740711   \n",
       "22               0.908232           0.436801             0.749266   \n",
       "23               0.909832           0.435814             0.744456   \n",
       "24               0.901861           0.448837             0.720865   \n",
       "25               0.777678           0.720130             0.660857   \n",
       "26               0.779711           0.721768             0.670714   \n",
       "27               0.783739           0.712005             0.697282   \n",
       "28               0.773575           0.729394             0.675801   \n",
       "29               0.773854           0.723447             0.654816   \n",
       "\n",
       "    lipo_valid_rmse  lipo_test_pearsonr  lipo_test_rmse  \\\n",
       "0          0.769643            0.531337        0.782116   \n",
       "1          0.806719            0.514140        0.788926   \n",
       "2          0.797949            0.509164        0.795617   \n",
       "3          0.815365            0.503509        0.800754   \n",
       "4          0.804004            0.507554        0.796507   \n",
       "5          0.823305            0.512566        0.806596   \n",
       "6          0.813351            0.524219        0.790027   \n",
       "7          0.807255            0.505320        0.812510   \n",
       "8          0.835626            0.447331        0.826765   \n",
       "9          0.827344            0.491301        0.799713   \n",
       "10         0.750743            0.680795        0.696812   \n",
       "11         0.727463            0.713709        0.677001   \n",
       "12         0.730614            0.702685        0.676545   \n",
       "13         0.742473            0.701187        0.683299   \n",
       "14         0.724182            0.706217        0.674961   \n",
       "15         0.827611            0.510875        0.805915   \n",
       "16         0.832074            0.503531        0.806500   \n",
       "17         0.827933            0.470739        0.836043   \n",
       "18         0.828532            0.528177        0.788722   \n",
       "19         0.823751            0.529007        0.794890   \n",
       "20         0.705519            0.722884        0.665679   \n",
       "21         0.735474            0.717953        0.696740   \n",
       "22         0.700821            0.733807        0.657533   \n",
       "23         0.712699            0.712487        0.683005   \n",
       "24         0.734076            0.692787        0.692444   \n",
       "25         0.759722            0.582182        0.750324   \n",
       "26         0.746713            0.624257        0.717793   \n",
       "27         0.730289            0.663698        0.696253   \n",
       "28         0.747815            0.633899        0.718338   \n",
       "29         0.768090            0.565669        0.759907   \n",
       "\n",
       "    tox21_valid_roc_auc_score  tox21_valid_average_precision_score  \\\n",
       "0                    0.782730                             0.409358   \n",
       "1                    0.761625                             0.408209   \n",
       "2                    0.769647                             0.426420   \n",
       "3                    0.776381                             0.431358   \n",
       "4                    0.780156                             0.400269   \n",
       "5                    0.762783                             0.412171   \n",
       "6                    0.761239                             0.368507   \n",
       "7                    0.734858                             0.433442   \n",
       "8                    0.762268                             0.433016   \n",
       "9                    0.785904                             0.453306   \n",
       "10                   0.770290                             0.429965   \n",
       "11                   0.769775                             0.427343   \n",
       "12                   0.772049                             0.429428   \n",
       "13                   0.766730                             0.428032   \n",
       "14                   0.771577                             0.429924   \n",
       "15                   0.739662                             0.390483   \n",
       "16                   0.741421                             0.419757   \n",
       "17                   0.738418                             0.435662   \n",
       "18                   0.740520                             0.381594   \n",
       "19                   0.716970                             0.382302   \n",
       "20                   0.783717                             0.472981   \n",
       "21                   0.786676                             0.469447   \n",
       "22                   0.777239                             0.451759   \n",
       "23                   0.755920                             0.419479   \n",
       "24                   0.780285                             0.474502   \n",
       "25                   0.735308                             0.404245   \n",
       "26                   0.730268                             0.414122   \n",
       "27                   0.709463                             0.432810   \n",
       "28                   0.700969                             0.360835   \n",
       "29                   0.722268                             0.380278   \n",
       "\n",
       "    tox21_test_roc_auc_score  tox21_test_average_precision_score  \n",
       "0                   0.724644                            0.319663  \n",
       "1                   0.771858                            0.277485  \n",
       "2                   0.751504                            0.299939  \n",
       "3                   0.738343                            0.287014  \n",
       "4                   0.740154                            0.308734  \n",
       "5                   0.729537                            0.286098  \n",
       "6                   0.741719                            0.285398  \n",
       "7                   0.745780                            0.299844  \n",
       "8                   0.737609                            0.343815  \n",
       "9                   0.746074                            0.306306  \n",
       "10                  0.752287                            0.392007  \n",
       "11                  0.752777                            0.402069  \n",
       "12                  0.755908                            0.393549  \n",
       "13                  0.750330                            0.381192  \n",
       "14                  0.750917                            0.390249  \n",
       "15                  0.761975                            0.334774  \n",
       "16                  0.753804                            0.325718  \n",
       "17                  0.750183                            0.348128  \n",
       "18                  0.766574                            0.373289  \n",
       "19                  0.736093                            0.346758  \n",
       "20                  0.740594                            0.352845  \n",
       "21                  0.732325                            0.357853  \n",
       "22                  0.745389                            0.366156  \n",
       "23                  0.734185                            0.352519  \n",
       "24                  0.748031                            0.358638  \n",
       "25                  0.730173                            0.378770  \n",
       "26                  0.712804                            0.345822  \n",
       "27                  0.715593                            0.341018  \n",
       "28                  0.724546                            0.379368  \n",
       "29                  0.722491                            0.316989  \n",
       "\n",
       "[30 rows x 42 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c2100cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_avg_df.to_csv('ft_results_combined.csv', index=False)\n",
    "combined_all_df.to_csv('ft_results_all_seeds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574c1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reverie_env_new] *",
   "language": "python",
   "name": "conda-env-reverie_env_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
