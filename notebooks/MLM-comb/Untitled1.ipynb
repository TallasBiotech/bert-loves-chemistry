{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0b396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64f9fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mlm_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a688e248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clintox_valid_roc_auc_score_mean</th>\n",
       "      <th>clintox_valid_average_precision_score_mean</th>\n",
       "      <th>clintox_test_roc_auc_score_mean</th>\n",
       "      <th>clintox_test_average_precision_score_mean</th>\n",
       "      <th>tox21_valid_roc_auc_score_mean</th>\n",
       "      <th>tox21_valid_average_precision_score_mean</th>\n",
       "      <th>tox21_test_roc_auc_score_mean</th>\n",
       "      <th>tox21_test_average_precision_score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.630516</td>\n",
       "      <td>0.978756</td>\n",
       "      <td>0.673461</td>\n",
       "      <td>0.968323</td>\n",
       "      <td>0.776767</td>\n",
       "      <td>0.457633</td>\n",
       "      <td>0.740105</td>\n",
       "      <td>0.357602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.630516</td>\n",
       "      <td>0.978756</td>\n",
       "      <td>0.673461</td>\n",
       "      <td>0.968323</td>\n",
       "      <td>0.776767</td>\n",
       "      <td>0.457633</td>\n",
       "      <td>0.740105</td>\n",
       "      <td>0.357602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.691901</td>\n",
       "      <td>0.981461</td>\n",
       "      <td>0.520943</td>\n",
       "      <td>0.947481</td>\n",
       "      <td>0.719655</td>\n",
       "      <td>0.398458</td>\n",
       "      <td>0.721121</td>\n",
       "      <td>0.352393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.696009</td>\n",
       "      <td>0.981225</td>\n",
       "      <td>0.653157</td>\n",
       "      <td>0.968030</td>\n",
       "      <td>0.768428</td>\n",
       "      <td>0.480094</td>\n",
       "      <td>0.763433</td>\n",
       "      <td>0.344838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.691901</td>\n",
       "      <td>0.981461</td>\n",
       "      <td>0.520943</td>\n",
       "      <td>0.947481</td>\n",
       "      <td>0.719655</td>\n",
       "      <td>0.398458</td>\n",
       "      <td>0.721121</td>\n",
       "      <td>0.352393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.652347</td>\n",
       "      <td>0.980267</td>\n",
       "      <td>0.642926</td>\n",
       "      <td>0.959157</td>\n",
       "      <td>0.685707</td>\n",
       "      <td>0.414530</td>\n",
       "      <td>0.763036</td>\n",
       "      <td>0.348931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.533568</td>\n",
       "      <td>0.967134</td>\n",
       "      <td>0.637490</td>\n",
       "      <td>0.957297</td>\n",
       "      <td>0.735398</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.753726</td>\n",
       "      <td>0.345733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.453756</td>\n",
       "      <td>0.950809</td>\n",
       "      <td>0.639728</td>\n",
       "      <td>0.965542</td>\n",
       "      <td>0.774108</td>\n",
       "      <td>0.415123</td>\n",
       "      <td>0.745301</td>\n",
       "      <td>0.298567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.453756</td>\n",
       "      <td>0.950809</td>\n",
       "      <td>0.639728</td>\n",
       "      <td>0.965542</td>\n",
       "      <td>0.774108</td>\n",
       "      <td>0.415123</td>\n",
       "      <td>0.745301</td>\n",
       "      <td>0.298567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.533568</td>\n",
       "      <td>0.967134</td>\n",
       "      <td>0.637490</td>\n",
       "      <td>0.957297</td>\n",
       "      <td>0.735398</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.753726</td>\n",
       "      <td>0.345733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.463615</td>\n",
       "      <td>0.962117</td>\n",
       "      <td>0.557954</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.802428</td>\n",
       "      <td>0.492139</td>\n",
       "      <td>0.737463</td>\n",
       "      <td>0.312435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.723474</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.559153</td>\n",
       "      <td>0.945464</td>\n",
       "      <td>0.771354</td>\n",
       "      <td>0.408372</td>\n",
       "      <td>0.718362</td>\n",
       "      <td>0.309210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.706573</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.652838</td>\n",
       "      <td>0.969040</td>\n",
       "      <td>0.761410</td>\n",
       "      <td>0.420089</td>\n",
       "      <td>0.740144</td>\n",
       "      <td>0.304292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.706573</td>\n",
       "      <td>0.984093</td>\n",
       "      <td>0.652838</td>\n",
       "      <td>0.969040</td>\n",
       "      <td>0.761410</td>\n",
       "      <td>0.420089</td>\n",
       "      <td>0.740144</td>\n",
       "      <td>0.304292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.784272</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.474101</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.745444</td>\n",
       "      <td>0.379362</td>\n",
       "      <td>0.743784</td>\n",
       "      <td>0.264033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clintox_valid_roc_auc_score_mean  \\\n",
       "0                           0.630516   \n",
       "1                           0.630516   \n",
       "2                           0.691901   \n",
       "3                           0.696009   \n",
       "4                           0.691901   \n",
       "5                           0.652347   \n",
       "6                           0.533568   \n",
       "7                           0.453756   \n",
       "8                           0.453756   \n",
       "9                           0.533568   \n",
       "10                          0.463615   \n",
       "11                          0.723474   \n",
       "12                          0.706573   \n",
       "13                          0.706573   \n",
       "14                          0.784272   \n",
       "\n",
       "    clintox_valid_average_precision_score_mean  \\\n",
       "0                                     0.978756   \n",
       "1                                     0.978756   \n",
       "2                                     0.981461   \n",
       "3                                     0.981225   \n",
       "4                                     0.981461   \n",
       "5                                     0.980267   \n",
       "6                                     0.967134   \n",
       "7                                     0.950809   \n",
       "8                                     0.950809   \n",
       "9                                     0.967134   \n",
       "10                                    0.962117   \n",
       "11                                    0.984925   \n",
       "12                                    0.984093   \n",
       "13                                    0.984093   \n",
       "14                                    0.989333   \n",
       "\n",
       "    clintox_test_roc_auc_score_mean  \\\n",
       "0                          0.673461   \n",
       "1                          0.673461   \n",
       "2                          0.520943   \n",
       "3                          0.653157   \n",
       "4                          0.520943   \n",
       "5                          0.642926   \n",
       "6                          0.637490   \n",
       "7                          0.639728   \n",
       "8                          0.639728   \n",
       "9                          0.637490   \n",
       "10                         0.557954   \n",
       "11                         0.559153   \n",
       "12                         0.652838   \n",
       "13                         0.652838   \n",
       "14                         0.474101   \n",
       "\n",
       "    clintox_test_average_precision_score_mean  tox21_valid_roc_auc_score_mean  \\\n",
       "0                                    0.968323                        0.776767   \n",
       "1                                    0.968323                        0.776767   \n",
       "2                                    0.947481                        0.719655   \n",
       "3                                    0.968030                        0.768428   \n",
       "4                                    0.947481                        0.719655   \n",
       "5                                    0.959157                        0.685707   \n",
       "6                                    0.957297                        0.735398   \n",
       "7                                    0.965542                        0.774108   \n",
       "8                                    0.965542                        0.774108   \n",
       "9                                    0.957297                        0.735398   \n",
       "10                                   0.954819                        0.802428   \n",
       "11                                   0.945464                        0.771354   \n",
       "12                                   0.969040                        0.761410   \n",
       "13                                   0.969040                        0.761410   \n",
       "14                                   0.934783                        0.745444   \n",
       "\n",
       "    tox21_valid_average_precision_score_mean  tox21_test_roc_auc_score_mean  \\\n",
       "0                                   0.457633                       0.740105   \n",
       "1                                   0.457633                       0.740105   \n",
       "2                                   0.398458                       0.721121   \n",
       "3                                   0.480094                       0.763433   \n",
       "4                                   0.398458                       0.721121   \n",
       "5                                   0.414530                       0.763036   \n",
       "6                                   0.401960                       0.753726   \n",
       "7                                   0.415123                       0.745301   \n",
       "8                                   0.415123                       0.745301   \n",
       "9                                   0.401960                       0.753726   \n",
       "10                                  0.492139                       0.737463   \n",
       "11                                  0.408372                       0.718362   \n",
       "12                                  0.420089                       0.740144   \n",
       "13                                  0.420089                       0.740144   \n",
       "14                                  0.379362                       0.743784   \n",
       "\n",
       "    tox21_test_average_precision_score_mean  \n",
       "0                                  0.357602  \n",
       "1                                  0.357602  \n",
       "2                                  0.352393  \n",
       "3                                  0.344838  \n",
       "4                                  0.352393  \n",
       "5                                  0.348931  \n",
       "6                                  0.345733  \n",
       "7                                  0.298567  \n",
       "8                                  0.298567  \n",
       "9                                  0.345733  \n",
       "10                                 0.312435  \n",
       "11                                 0.309210  \n",
       "12                                 0.304292  \n",
       "13                                 0.304292  \n",
       "14                                 0.264033  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(like='tox').filter(like='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea998c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>min_eval_loss</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>attention_probs_dropout_prob</th>\n",
       "      <th>hidden_dropout_prob</th>\n",
       "      <th>intermediate_size</th>\n",
       "      <th>num_attention_heads</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>pretraining_task</th>\n",
       "      <th>...</th>\n",
       "      <th>delaney_test_rmse_mean</th>\n",
       "      <th>delaney_test_rmse_std</th>\n",
       "      <th>lipo_valid_rmse_mean</th>\n",
       "      <th>lipo_valid_rmse_std</th>\n",
       "      <th>lipo_test_rmse_mean</th>\n",
       "      <th>lipo_test_rmse_std</th>\n",
       "      <th>tox21_valid_average_precision_score_mean</th>\n",
       "      <th>tox21_valid_average_precision_score_std</th>\n",
       "      <th>tox21_test_average_precision_score_mean</th>\n",
       "      <th>tox21_test_average_precision_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlm_run_45</td>\n",
       "      <td>0.136374</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439621</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.717718</td>\n",
       "      <td>0.014439</td>\n",
       "      <td>0.679080</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>0.457633</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>0.357602</td>\n",
       "      <td>0.004955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlm_run_45</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439621</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.717718</td>\n",
       "      <td>0.014439</td>\n",
       "      <td>0.679080</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>0.457633</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>0.357602</td>\n",
       "      <td>0.004955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlm_run_19</td>\n",
       "      <td>0.168913</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721349</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.750526</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.728523</td>\n",
       "      <td>0.023326</td>\n",
       "      <td>0.398458</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>0.352393</td>\n",
       "      <td>0.023872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlm_run_45</td>\n",
       "      <td>0.180579</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>5M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445916</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.757503</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.721880</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.480094</td>\n",
       "      <td>0.012952</td>\n",
       "      <td>0.344838</td>\n",
       "      <td>0.006467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlm_run_19</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721349</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.750526</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.728523</td>\n",
       "      <td>0.023326</td>\n",
       "      <td>0.398458</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>0.352393</td>\n",
       "      <td>0.023872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlm_run_19</td>\n",
       "      <td>0.251964</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>5M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586834</td>\n",
       "      <td>0.024843</td>\n",
       "      <td>0.765871</td>\n",
       "      <td>0.012883</td>\n",
       "      <td>0.731868</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>0.414530</td>\n",
       "      <td>0.014435</td>\n",
       "      <td>0.348931</td>\n",
       "      <td>0.007947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mlm_run_38</td>\n",
       "      <td>0.386785</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631406</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.827980</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.806414</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.345733</td>\n",
       "      <td>0.016043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlm_run_39</td>\n",
       "      <td>0.421750</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503508</td>\n",
       "      <td>0.024869</td>\n",
       "      <td>0.798736</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>0.792784</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.415123</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.298567</td>\n",
       "      <td>0.015021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mlm_run_39</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503508</td>\n",
       "      <td>0.024869</td>\n",
       "      <td>0.798736</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>0.792784</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.415123</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.298567</td>\n",
       "      <td>0.015021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mlm_run_38</td>\n",
       "      <td>0.457947</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631406</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.827980</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.806414</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.345733</td>\n",
       "      <td>0.016043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mlm_run_38</td>\n",
       "      <td>0.496019</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>5M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931558</td>\n",
       "      <td>0.133228</td>\n",
       "      <td>0.837930</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.793085</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.492139</td>\n",
       "      <td>0.013011</td>\n",
       "      <td>0.312435</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlm_run_39</td>\n",
       "      <td>0.512588</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508937</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.767842</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>0.741103</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>0.408372</td>\n",
       "      <td>0.026602</td>\n",
       "      <td>0.309210</td>\n",
       "      <td>0.020414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mlm_run_11</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553949</td>\n",
       "      <td>0.028713</td>\n",
       "      <td>0.821376</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>0.807122</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.420089</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>0.304292</td>\n",
       "      <td>0.021326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mlm_run_11</td>\n",
       "      <td>0.615919</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553949</td>\n",
       "      <td>0.028713</td>\n",
       "      <td>0.821376</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>0.807122</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.420089</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>0.304292</td>\n",
       "      <td>0.021326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mlm_run_11</td>\n",
       "      <td>0.695174</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755076</td>\n",
       "      <td>0.027707</td>\n",
       "      <td>0.802092</td>\n",
       "      <td>0.014718</td>\n",
       "      <td>0.801712</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.379362</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>0.264033</td>\n",
       "      <td>0.009164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      run_name  min_eval_loss  hidden_size  attention_probs_dropout_prob  \\\n",
       "0   mlm_run_45       0.136374          384                         0.109   \n",
       "1   mlm_run_45       0.147017          384                         0.109   \n",
       "2   mlm_run_19       0.168913           57                         0.129   \n",
       "3   mlm_run_45       0.180579          384                         0.109   \n",
       "4   mlm_run_19       0.196440           57                         0.129   \n",
       "5   mlm_run_19       0.251964           57                         0.129   \n",
       "6   mlm_run_38       0.386785          126                         0.109   \n",
       "7   mlm_run_39       0.421750          209                         0.176   \n",
       "8   mlm_run_39       0.429169          209                         0.176   \n",
       "9   mlm_run_38       0.457947          126                         0.109   \n",
       "10  mlm_run_38       0.496019          126                         0.109   \n",
       "11  mlm_run_39       0.512588          209                         0.176   \n",
       "12  mlm_run_11       0.578779          112                         0.118   \n",
       "13  mlm_run_11       0.615919          112                         0.118   \n",
       "14  mlm_run_11       0.695174          112                         0.118   \n",
       "\n",
       "    hidden_dropout_prob  intermediate_size  num_attention_heads  \\\n",
       "0                 0.144                464                   12   \n",
       "1                 0.144                464                   12   \n",
       "2                 0.139              10476                    3   \n",
       "3                 0.144                464                   12   \n",
       "4                 0.139              10476                    3   \n",
       "5                 0.139              10476                    3   \n",
       "6                 0.279                456                    3   \n",
       "7                 0.128               3968                   11   \n",
       "8                 0.128               3968                   11   \n",
       "9                 0.279                456                    3   \n",
       "10                0.279                456                    3   \n",
       "11                0.128               3968                   11   \n",
       "12                0.183               4844                    8   \n",
       "13                0.183               4844                    8   \n",
       "14                0.183               4844                    8   \n",
       "\n",
       "    num_hidden_layers  learning_rate pretraining_task  ...  \\\n",
       "0                   3       0.000141          77M-MLM  ...   \n",
       "1                   3       0.000141          10M-MLM  ...   \n",
       "2                   5       0.000058          77M-MLM  ...   \n",
       "3                   3       0.000141           5M-MLM  ...   \n",
       "4                   5       0.000058          10M-MLM  ...   \n",
       "5                   5       0.000058           5M-MLM  ...   \n",
       "6                   2       0.000021          77M-MLM  ...   \n",
       "7                   3       0.000002          77M-MLM  ...   \n",
       "8                   3       0.000002          10M-MLM  ...   \n",
       "9                   2       0.000021          10M-MLM  ...   \n",
       "10                  2       0.000021           5M-MLM  ...   \n",
       "11                  3       0.000002           5M-MLM  ...   \n",
       "12                  5       0.000002          77M-MLM  ...   \n",
       "13                  5       0.000002          10M-MLM  ...   \n",
       "14                  5       0.000002           5M-MLM  ...   \n",
       "\n",
       "    delaney_test_rmse_mean  delaney_test_rmse_std  lipo_valid_rmse_mean  \\\n",
       "0                 0.439621               0.005050              0.717718   \n",
       "1                 0.439621               0.005050              0.717718   \n",
       "2                 0.721349               0.005623              0.750526   \n",
       "3                 0.445916               0.005803              0.757503   \n",
       "4                 0.721349               0.005623              0.750526   \n",
       "5                 0.586834               0.024843              0.765871   \n",
       "6                 0.631406               0.008050              0.827980   \n",
       "7                 0.503508               0.024869              0.798736   \n",
       "8                 0.503508               0.024869              0.798736   \n",
       "9                 0.631406               0.008050              0.827980   \n",
       "10                0.931558               0.133228              0.837930   \n",
       "11                0.508937               0.028512              0.767842   \n",
       "12                0.553949               0.028713              0.821376   \n",
       "13                0.553949               0.028713              0.821376   \n",
       "14                0.755076               0.027707              0.802092   \n",
       "\n",
       "    lipo_valid_rmse_std  lipo_test_rmse_mean  lipo_test_rmse_std  \\\n",
       "0              0.014439             0.679080            0.015164   \n",
       "1              0.014439             0.679080            0.015164   \n",
       "2              0.012841             0.728523            0.023326   \n",
       "3              0.003669             0.721880            0.003496   \n",
       "4              0.012841             0.728523            0.023326   \n",
       "5              0.012883             0.731868            0.008482   \n",
       "6              0.002649             0.806414            0.016272   \n",
       "7              0.015589             0.792784            0.006544   \n",
       "8              0.015589             0.792784            0.006544   \n",
       "9              0.002649             0.806414            0.016272   \n",
       "10             0.003785             0.793085            0.002934   \n",
       "11             0.010263             0.741103            0.014695   \n",
       "12             0.010062             0.807122            0.012347   \n",
       "13             0.010062             0.807122            0.012347   \n",
       "14             0.014718             0.801712            0.013233   \n",
       "\n",
       "    tox21_valid_average_precision_score_mean  \\\n",
       "0                                   0.457633   \n",
       "1                                   0.457633   \n",
       "2                                   0.398458   \n",
       "3                                   0.480094   \n",
       "4                                   0.398458   \n",
       "5                                   0.414530   \n",
       "6                                   0.401960   \n",
       "7                                   0.415123   \n",
       "8                                   0.415123   \n",
       "9                                   0.401960   \n",
       "10                                  0.492139   \n",
       "11                                  0.408372   \n",
       "12                                  0.420089   \n",
       "13                                  0.420089   \n",
       "14                                  0.379362   \n",
       "\n",
       "    tox21_valid_average_precision_score_std  \\\n",
       "0                                  0.020736   \n",
       "1                                  0.020736   \n",
       "2                                  0.025318   \n",
       "3                                  0.012952   \n",
       "4                                  0.025318   \n",
       "5                                  0.014435   \n",
       "6                                  0.021842   \n",
       "7                                  0.011772   \n",
       "8                                  0.011772   \n",
       "9                                  0.021842   \n",
       "10                                 0.013011   \n",
       "11                                 0.026602   \n",
       "12                                 0.028887   \n",
       "13                                 0.028887   \n",
       "14                                 0.022225   \n",
       "\n",
       "    tox21_test_average_precision_score_mean  \\\n",
       "0                                  0.357602   \n",
       "1                                  0.357602   \n",
       "2                                  0.352393   \n",
       "3                                  0.344838   \n",
       "4                                  0.352393   \n",
       "5                                  0.348931   \n",
       "6                                  0.345733   \n",
       "7                                  0.298567   \n",
       "8                                  0.298567   \n",
       "9                                  0.345733   \n",
       "10                                 0.312435   \n",
       "11                                 0.309210   \n",
       "12                                 0.304292   \n",
       "13                                 0.304292   \n",
       "14                                 0.264033   \n",
       "\n",
       "    tox21_test_average_precision_score_std  \n",
       "0                                 0.004955  \n",
       "1                                 0.004955  \n",
       "2                                 0.023872  \n",
       "3                                 0.006467  \n",
       "4                                 0.023872  \n",
       "5                                 0.007947  \n",
       "6                                 0.016043  \n",
       "7                                 0.015021  \n",
       "8                                 0.015021  \n",
       "9                                 0.016043  \n",
       "10                                0.016000  \n",
       "11                                0.020414  \n",
       "12                                0.021326  \n",
       "13                                0.021326  \n",
       "14                                0.009164  \n",
       "\n",
       "[15 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reverie_env_new] *",
   "language": "python",
   "name": "conda-env-reverie_env_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
