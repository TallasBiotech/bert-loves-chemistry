{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc5592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b916d0",
   "metadata": {},
   "source": [
    "Load in `.csv` file that came from `stage-p2x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1c608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('runs_with_eval_loss_and_params.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73bfa20",
   "metadata": {},
   "source": [
    "Load in data from MolNet finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52340b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168a9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366fb3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adfead7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bucket = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ead70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_dir = f\"s3://{model_bucket}/chemberta/mlm_pretraining_77M_20210729/molnet_mlm_77M_ft_20210729/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe967dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(cloud_dir):\n",
    "    run_dirs = fs.ls(cloud_dir)\n",
    "    data_avg = []\n",
    "    df_all = pd.DataFrame()\n",
    "    for rd in run_dirs:\n",
    "        run_name = os.path.basename(os.path.normpath(rd))\n",
    "        # go one level down to get the molnet task\n",
    "        molnet_task_data_avg = {}\n",
    "        molnet_task_data_all = {}\n",
    "        for molnet_task_dir in fs.ls(rd):\n",
    "            molnet_task_name = os.path.basename(os.path.normpath(molnet_task_dir))\n",
    "            results_dir = os.path.join(molnet_task_dir, \"results/\")\n",
    "            for subset in [\"valid\", \"test\"]:\n",
    "                with fs.open(os.path.join(results_dir, subset, \"metrics.json\")) as f:\n",
    "                    metrics = json.load(f)\n",
    "                # pick first item to get the keys\n",
    "                metric_names = list(list(metrics.items())[0][1].keys())\n",
    "                metric_res = {mn: [] for mn in metric_names}\n",
    "                for seed, res in metrics.items():\n",
    "                    for mn, mres in res.items():\n",
    "                        if mn == \"pearsonr\":\n",
    "                            metric_res[mn].append(mres[0])\n",
    "                        else:\n",
    "                            metric_res[mn].append(mres)\n",
    "                molnet_task_data_all.update({f\"{molnet_task_name}_{subset}_{mn}\": metric_res[mn] for mn in metric_names})\n",
    "                average_metrics = {f\"{molnet_task_name}_{subset}_{mn}_mean\": np.mean(metric_res[mn]) for mn in metric_names}\n",
    "                std_metrics = {f\"{molnet_task_name}_{subset}_{mn}_std\": np.std(metric_res[mn]) for mn in metric_names}\n",
    "                molnet_task_data_avg.update({**average_metrics, **std_metrics})\n",
    "        molnet_task_data_all.update({\"run_name\": [run_name]*5})\n",
    "        df_all = df_all.append(pd.DataFrame(molnet_task_data_all))\n",
    "        data_avg.append({\"run_name\": run_name, **molnet_task_data_avg})\n",
    "\n",
    "    df_avg = pd.DataFrame(data_avg)\n",
    "    return df_all, df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad87214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all, df_avg = get_dataframes(cloud_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37f75bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bace_classification_valid_roc_auc_score</th>\n",
       "      <th>bace_classification_valid_average_precision_score</th>\n",
       "      <th>bace_classification_test_roc_auc_score</th>\n",
       "      <th>bace_classification_test_average_precision_score</th>\n",
       "      <th>bace_regression_valid_pearsonr</th>\n",
       "      <th>bace_regression_valid_rmse</th>\n",
       "      <th>bace_regression_test_pearsonr</th>\n",
       "      <th>bace_regression_test_rmse</th>\n",
       "      <th>bbbp_valid_roc_auc_score</th>\n",
       "      <th>bbbp_valid_average_precision_score</th>\n",
       "      <th>...</th>\n",
       "      <th>delaney_test_rmse</th>\n",
       "      <th>lipo_valid_pearsonr</th>\n",
       "      <th>lipo_valid_rmse</th>\n",
       "      <th>lipo_test_pearsonr</th>\n",
       "      <th>lipo_test_rmse</th>\n",
       "      <th>tox21_valid_roc_auc_score</th>\n",
       "      <th>tox21_valid_average_precision_score</th>\n",
       "      <th>tox21_test_roc_auc_score</th>\n",
       "      <th>tox21_test_average_precision_score</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.658138</td>\n",
       "      <td>0.731607</td>\n",
       "      <td>0.769022</td>\n",
       "      <td>0.812590</td>\n",
       "      <td>0.025686</td>\n",
       "      <td>0.520232</td>\n",
       "      <td>0.775713</td>\n",
       "      <td>1.088148</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.954161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557614</td>\n",
       "      <td>0.587488</td>\n",
       "      <td>0.814128</td>\n",
       "      <td>0.469805</td>\n",
       "      <td>0.812314</td>\n",
       "      <td>0.717914</td>\n",
       "      <td>0.319912</td>\n",
       "      <td>0.745829</td>\n",
       "      <td>0.285211</td>\n",
       "      <td>run_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.692786</td>\n",
       "      <td>0.730077</td>\n",
       "      <td>0.806703</td>\n",
       "      <td>0.850360</td>\n",
       "      <td>0.041414</td>\n",
       "      <td>0.524236</td>\n",
       "      <td>0.767800</td>\n",
       "      <td>1.093925</td>\n",
       "      <td>0.664596</td>\n",
       "      <td>0.673363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587209</td>\n",
       "      <td>0.608315</td>\n",
       "      <td>0.799419</td>\n",
       "      <td>0.510296</td>\n",
       "      <td>0.795680</td>\n",
       "      <td>0.769175</td>\n",
       "      <td>0.383500</td>\n",
       "      <td>0.731151</td>\n",
       "      <td>0.302215</td>\n",
       "      <td>run_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.676084</td>\n",
       "      <td>0.750218</td>\n",
       "      <td>0.797283</td>\n",
       "      <td>0.824736</td>\n",
       "      <td>0.034139</td>\n",
       "      <td>0.508618</td>\n",
       "      <td>0.786691</td>\n",
       "      <td>1.080424</td>\n",
       "      <td>0.953028</td>\n",
       "      <td>0.955238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577331</td>\n",
       "      <td>0.577650</td>\n",
       "      <td>0.821567</td>\n",
       "      <td>0.477865</td>\n",
       "      <td>0.817874</td>\n",
       "      <td>0.756778</td>\n",
       "      <td>0.390135</td>\n",
       "      <td>0.743138</td>\n",
       "      <td>0.261230</td>\n",
       "      <td>run_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.657249</td>\n",
       "      <td>0.722960</td>\n",
       "      <td>0.787319</td>\n",
       "      <td>0.825685</td>\n",
       "      <td>0.062565</td>\n",
       "      <td>0.510056</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>1.074092</td>\n",
       "      <td>0.955648</td>\n",
       "      <td>0.955838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534699</td>\n",
       "      <td>0.566758</td>\n",
       "      <td>0.828631</td>\n",
       "      <td>0.488899</td>\n",
       "      <td>0.813623</td>\n",
       "      <td>0.747083</td>\n",
       "      <td>0.349745</td>\n",
       "      <td>0.738784</td>\n",
       "      <td>0.259383</td>\n",
       "      <td>run_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.688699</td>\n",
       "      <td>0.728319</td>\n",
       "      <td>0.805435</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.043745</td>\n",
       "      <td>0.524860</td>\n",
       "      <td>0.775766</td>\n",
       "      <td>1.103782</td>\n",
       "      <td>0.733307</td>\n",
       "      <td>0.715206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551188</td>\n",
       "      <td>0.585450</td>\n",
       "      <td>0.815250</td>\n",
       "      <td>0.474445</td>\n",
       "      <td>0.818551</td>\n",
       "      <td>0.739490</td>\n",
       "      <td>0.368941</td>\n",
       "      <td>0.726993</td>\n",
       "      <td>0.269691</td>\n",
       "      <td>run_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.684435</td>\n",
       "      <td>0.682067</td>\n",
       "      <td>0.778623</td>\n",
       "      <td>0.818933</td>\n",
       "      <td>0.386013</td>\n",
       "      <td>0.526491</td>\n",
       "      <td>0.696960</td>\n",
       "      <td>1.066217</td>\n",
       "      <td>0.646060</td>\n",
       "      <td>0.700208</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089734</td>\n",
       "      <td>0.675606</td>\n",
       "      <td>0.744013</td>\n",
       "      <td>0.611014</td>\n",
       "      <td>0.727990</td>\n",
       "      <td>0.695908</td>\n",
       "      <td>0.389212</td>\n",
       "      <td>0.708303</td>\n",
       "      <td>0.330024</td>\n",
       "      <td>run_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663824</td>\n",
       "      <td>0.657262</td>\n",
       "      <td>0.787138</td>\n",
       "      <td>0.819535</td>\n",
       "      <td>0.351971</td>\n",
       "      <td>0.519460</td>\n",
       "      <td>0.698363</td>\n",
       "      <td>1.084981</td>\n",
       "      <td>0.647807</td>\n",
       "      <td>0.701861</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089348</td>\n",
       "      <td>0.658490</td>\n",
       "      <td>0.759977</td>\n",
       "      <td>0.588983</td>\n",
       "      <td>0.742809</td>\n",
       "      <td>0.698181</td>\n",
       "      <td>0.351627</td>\n",
       "      <td>0.718822</td>\n",
       "      <td>0.373326</td>\n",
       "      <td>run_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.672175</td>\n",
       "      <td>0.655272</td>\n",
       "      <td>0.783514</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.380552</td>\n",
       "      <td>0.522898</td>\n",
       "      <td>0.706767</td>\n",
       "      <td>1.103609</td>\n",
       "      <td>0.651203</td>\n",
       "      <td>0.702432</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089461</td>\n",
       "      <td>0.651133</td>\n",
       "      <td>0.768026</td>\n",
       "      <td>0.580118</td>\n",
       "      <td>0.746829</td>\n",
       "      <td>0.708219</td>\n",
       "      <td>0.392658</td>\n",
       "      <td>0.722614</td>\n",
       "      <td>0.316314</td>\n",
       "      <td>run_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676262</td>\n",
       "      <td>0.663668</td>\n",
       "      <td>0.781522</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.380487</td>\n",
       "      <td>0.528667</td>\n",
       "      <td>0.683448</td>\n",
       "      <td>1.126033</td>\n",
       "      <td>0.649845</td>\n",
       "      <td>0.700853</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089637</td>\n",
       "      <td>0.675172</td>\n",
       "      <td>0.744739</td>\n",
       "      <td>0.606664</td>\n",
       "      <td>0.733963</td>\n",
       "      <td>0.706460</td>\n",
       "      <td>0.336662</td>\n",
       "      <td>0.723910</td>\n",
       "      <td>0.288643</td>\n",
       "      <td>run_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.685679</td>\n",
       "      <td>0.687578</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.825282</td>\n",
       "      <td>0.394321</td>\n",
       "      <td>0.535069</td>\n",
       "      <td>0.699458</td>\n",
       "      <td>1.130868</td>\n",
       "      <td>0.650718</td>\n",
       "      <td>0.703735</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090029</td>\n",
       "      <td>0.694749</td>\n",
       "      <td>0.729115</td>\n",
       "      <td>0.626268</td>\n",
       "      <td>0.723935</td>\n",
       "      <td>0.714203</td>\n",
       "      <td>0.384258</td>\n",
       "      <td>0.739811</td>\n",
       "      <td>0.314118</td>\n",
       "      <td>run_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.480633</td>\n",
       "      <td>0.581557</td>\n",
       "      <td>0.407790</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.200680</td>\n",
       "      <td>0.572452</td>\n",
       "      <td>0.796274</td>\n",
       "      <td>1.072090</td>\n",
       "      <td>0.587636</td>\n",
       "      <td>0.643216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786764</td>\n",
       "      <td>0.559995</td>\n",
       "      <td>0.841933</td>\n",
       "      <td>0.535669</td>\n",
       "      <td>0.785855</td>\n",
       "      <td>0.776896</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.739567</td>\n",
       "      <td>0.306432</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.480277</td>\n",
       "      <td>0.581420</td>\n",
       "      <td>0.407790</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.162325</td>\n",
       "      <td>0.574779</td>\n",
       "      <td>0.780949</td>\n",
       "      <td>1.108798</td>\n",
       "      <td>0.587539</td>\n",
       "      <td>0.643112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786426</td>\n",
       "      <td>0.580993</td>\n",
       "      <td>0.833033</td>\n",
       "      <td>0.556836</td>\n",
       "      <td>0.774574</td>\n",
       "      <td>0.775566</td>\n",
       "      <td>0.400353</td>\n",
       "      <td>0.755174</td>\n",
       "      <td>0.306817</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.480277</td>\n",
       "      <td>0.581420</td>\n",
       "      <td>0.407790</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.162855</td>\n",
       "      <td>0.579915</td>\n",
       "      <td>0.730097</td>\n",
       "      <td>1.170887</td>\n",
       "      <td>0.587636</td>\n",
       "      <td>0.643216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786868</td>\n",
       "      <td>0.550857</td>\n",
       "      <td>0.851559</td>\n",
       "      <td>0.494188</td>\n",
       "      <td>0.807679</td>\n",
       "      <td>0.785690</td>\n",
       "      <td>0.438065</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>0.305062</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.480455</td>\n",
       "      <td>0.581653</td>\n",
       "      <td>0.407790</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.140878</td>\n",
       "      <td>0.578404</td>\n",
       "      <td>0.633925</td>\n",
       "      <td>1.221884</td>\n",
       "      <td>0.587636</td>\n",
       "      <td>0.643359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785166</td>\n",
       "      <td>0.557717</td>\n",
       "      <td>0.841385</td>\n",
       "      <td>0.519508</td>\n",
       "      <td>0.791108</td>\n",
       "      <td>0.761024</td>\n",
       "      <td>0.414390</td>\n",
       "      <td>0.756984</td>\n",
       "      <td>0.295736</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.480277</td>\n",
       "      <td>0.581420</td>\n",
       "      <td>0.407790</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.183911</td>\n",
       "      <td>0.573742</td>\n",
       "      <td>0.803196</td>\n",
       "      <td>1.074786</td>\n",
       "      <td>0.587539</td>\n",
       "      <td>0.643178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784732</td>\n",
       "      <td>0.567456</td>\n",
       "      <td>0.840772</td>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.806044</td>\n",
       "      <td>0.752874</td>\n",
       "      <td>0.425464</td>\n",
       "      <td>0.749450</td>\n",
       "      <td>0.296878</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.677150</td>\n",
       "      <td>0.693762</td>\n",
       "      <td>0.769565</td>\n",
       "      <td>0.787230</td>\n",
       "      <td>0.157970</td>\n",
       "      <td>0.567084</td>\n",
       "      <td>0.570271</td>\n",
       "      <td>1.169818</td>\n",
       "      <td>0.948564</td>\n",
       "      <td>0.950652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500234</td>\n",
       "      <td>0.594244</td>\n",
       "      <td>0.810215</td>\n",
       "      <td>0.500075</td>\n",
       "      <td>0.802838</td>\n",
       "      <td>0.793926</td>\n",
       "      <td>0.476944</td>\n",
       "      <td>0.772005</td>\n",
       "      <td>0.315820</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.647655</td>\n",
       "      <td>0.669446</td>\n",
       "      <td>0.668659</td>\n",
       "      <td>0.761732</td>\n",
       "      <td>0.143197</td>\n",
       "      <td>0.574159</td>\n",
       "      <td>0.435992</td>\n",
       "      <td>1.234423</td>\n",
       "      <td>0.953319</td>\n",
       "      <td>0.956929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494843</td>\n",
       "      <td>0.635426</td>\n",
       "      <td>0.778865</td>\n",
       "      <td>0.533525</td>\n",
       "      <td>0.788924</td>\n",
       "      <td>0.782387</td>\n",
       "      <td>0.424622</td>\n",
       "      <td>0.716963</td>\n",
       "      <td>0.319807</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.670043</td>\n",
       "      <td>0.685364</td>\n",
       "      <td>0.742391</td>\n",
       "      <td>0.776272</td>\n",
       "      <td>0.152992</td>\n",
       "      <td>0.570695</td>\n",
       "      <td>0.554201</td>\n",
       "      <td>1.159993</td>\n",
       "      <td>0.948467</td>\n",
       "      <td>0.948413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506093</td>\n",
       "      <td>0.629760</td>\n",
       "      <td>0.781795</td>\n",
       "      <td>0.523192</td>\n",
       "      <td>0.791424</td>\n",
       "      <td>0.775523</td>\n",
       "      <td>0.429804</td>\n",
       "      <td>0.749743</td>\n",
       "      <td>0.281322</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.668443</td>\n",
       "      <td>0.687787</td>\n",
       "      <td>0.765761</td>\n",
       "      <td>0.793115</td>\n",
       "      <td>0.201737</td>\n",
       "      <td>0.575481</td>\n",
       "      <td>0.656452</td>\n",
       "      <td>1.105892</td>\n",
       "      <td>0.950602</td>\n",
       "      <td>0.950087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492666</td>\n",
       "      <td>0.604261</td>\n",
       "      <td>0.802144</td>\n",
       "      <td>0.490747</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0.768703</td>\n",
       "      <td>0.416913</td>\n",
       "      <td>0.741719</td>\n",
       "      <td>0.324869</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.667200</td>\n",
       "      <td>0.696945</td>\n",
       "      <td>0.666123</td>\n",
       "      <td>0.732940</td>\n",
       "      <td>0.165314</td>\n",
       "      <td>0.565029</td>\n",
       "      <td>0.623580</td>\n",
       "      <td>1.143062</td>\n",
       "      <td>0.946817</td>\n",
       "      <td>0.944321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511693</td>\n",
       "      <td>0.590478</td>\n",
       "      <td>0.813702</td>\n",
       "      <td>0.517507</td>\n",
       "      <td>0.790631</td>\n",
       "      <td>0.774708</td>\n",
       "      <td>0.429777</td>\n",
       "      <td>0.745976</td>\n",
       "      <td>0.338969</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613539</td>\n",
       "      <td>0.640570</td>\n",
       "      <td>0.560145</td>\n",
       "      <td>0.666911</td>\n",
       "      <td>0.152212</td>\n",
       "      <td>0.597335</td>\n",
       "      <td>0.344723</td>\n",
       "      <td>1.262163</td>\n",
       "      <td>0.957298</td>\n",
       "      <td>0.948095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.700273</td>\n",
       "      <td>0.742192</td>\n",
       "      <td>0.647553</td>\n",
       "      <td>0.722768</td>\n",
       "      <td>0.704272</td>\n",
       "      <td>0.409440</td>\n",
       "      <td>0.732374</td>\n",
       "      <td>0.329506</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613539</td>\n",
       "      <td>0.640570</td>\n",
       "      <td>0.560145</td>\n",
       "      <td>0.666911</td>\n",
       "      <td>0.152158</td>\n",
       "      <td>0.597264</td>\n",
       "      <td>0.344934</td>\n",
       "      <td>1.262140</td>\n",
       "      <td>0.958754</td>\n",
       "      <td>0.948394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513124</td>\n",
       "      <td>0.718443</td>\n",
       "      <td>0.734897</td>\n",
       "      <td>0.675877</td>\n",
       "      <td>0.713733</td>\n",
       "      <td>0.707962</td>\n",
       "      <td>0.413216</td>\n",
       "      <td>0.737756</td>\n",
       "      <td>0.335231</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.613539</td>\n",
       "      <td>0.640570</td>\n",
       "      <td>0.560326</td>\n",
       "      <td>0.668361</td>\n",
       "      <td>0.152103</td>\n",
       "      <td>0.597348</td>\n",
       "      <td>0.344833</td>\n",
       "      <td>1.262163</td>\n",
       "      <td>0.958269</td>\n",
       "      <td>0.948493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513691</td>\n",
       "      <td>0.740373</td>\n",
       "      <td>0.711280</td>\n",
       "      <td>0.693528</td>\n",
       "      <td>0.700368</td>\n",
       "      <td>0.704744</td>\n",
       "      <td>0.413110</td>\n",
       "      <td>0.736484</td>\n",
       "      <td>0.332703</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.613539</td>\n",
       "      <td>0.640570</td>\n",
       "      <td>0.560145</td>\n",
       "      <td>0.666911</td>\n",
       "      <td>0.152051</td>\n",
       "      <td>0.597339</td>\n",
       "      <td>0.344969</td>\n",
       "      <td>1.262159</td>\n",
       "      <td>0.958172</td>\n",
       "      <td>0.948613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511006</td>\n",
       "      <td>0.687219</td>\n",
       "      <td>0.751247</td>\n",
       "      <td>0.636140</td>\n",
       "      <td>0.726191</td>\n",
       "      <td>0.706889</td>\n",
       "      <td>0.418142</td>\n",
       "      <td>0.738539</td>\n",
       "      <td>0.331947</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.613539</td>\n",
       "      <td>0.640570</td>\n",
       "      <td>0.560145</td>\n",
       "      <td>0.666911</td>\n",
       "      <td>0.152146</td>\n",
       "      <td>0.597347</td>\n",
       "      <td>0.344777</td>\n",
       "      <td>1.262157</td>\n",
       "      <td>0.956425</td>\n",
       "      <td>0.944765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504182</td>\n",
       "      <td>0.689844</td>\n",
       "      <td>0.758536</td>\n",
       "      <td>0.634108</td>\n",
       "      <td>0.739025</td>\n",
       "      <td>0.701527</td>\n",
       "      <td>0.412342</td>\n",
       "      <td>0.732032</td>\n",
       "      <td>0.328458</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bace_classification_valid_roc_auc_score  \\\n",
       "0                                 0.658138   \n",
       "1                                 0.692786   \n",
       "2                                 0.676084   \n",
       "3                                 0.657249   \n",
       "4                                 0.688699   \n",
       "0                                 0.684435   \n",
       "1                                 0.663824   \n",
       "2                                 0.672175   \n",
       "3                                 0.676262   \n",
       "4                                 0.685679   \n",
       "0                                 0.480633   \n",
       "1                                 0.480277   \n",
       "2                                 0.480277   \n",
       "3                                 0.480455   \n",
       "4                                 0.480277   \n",
       "0                                 0.677150   \n",
       "1                                 0.647655   \n",
       "2                                 0.670043   \n",
       "3                                 0.668443   \n",
       "4                                 0.667200   \n",
       "0                                 0.613539   \n",
       "1                                 0.613539   \n",
       "2                                 0.613539   \n",
       "3                                 0.613539   \n",
       "4                                 0.613539   \n",
       "\n",
       "   bace_classification_valid_average_precision_score  \\\n",
       "0                                           0.731607   \n",
       "1                                           0.730077   \n",
       "2                                           0.750218   \n",
       "3                                           0.722960   \n",
       "4                                           0.728319   \n",
       "0                                           0.682067   \n",
       "1                                           0.657262   \n",
       "2                                           0.655272   \n",
       "3                                           0.663668   \n",
       "4                                           0.687578   \n",
       "0                                           0.581557   \n",
       "1                                           0.581420   \n",
       "2                                           0.581420   \n",
       "3                                           0.581653   \n",
       "4                                           0.581420   \n",
       "0                                           0.693762   \n",
       "1                                           0.669446   \n",
       "2                                           0.685364   \n",
       "3                                           0.687787   \n",
       "4                                           0.696945   \n",
       "0                                           0.640570   \n",
       "1                                           0.640570   \n",
       "2                                           0.640570   \n",
       "3                                           0.640570   \n",
       "4                                           0.640570   \n",
       "\n",
       "   bace_classification_test_roc_auc_score  \\\n",
       "0                                0.769022   \n",
       "1                                0.806703   \n",
       "2                                0.797283   \n",
       "3                                0.787319   \n",
       "4                                0.805435   \n",
       "0                                0.778623   \n",
       "1                                0.787138   \n",
       "2                                0.783514   \n",
       "3                                0.781522   \n",
       "4                                0.791667   \n",
       "0                                0.407790   \n",
       "1                                0.407790   \n",
       "2                                0.407790   \n",
       "3                                0.407790   \n",
       "4                                0.407790   \n",
       "0                                0.769565   \n",
       "1                                0.668659   \n",
       "2                                0.742391   \n",
       "3                                0.765761   \n",
       "4                                0.666123   \n",
       "0                                0.560145   \n",
       "1                                0.560145   \n",
       "2                                0.560326   \n",
       "3                                0.560145   \n",
       "4                                0.560145   \n",
       "\n",
       "   bace_classification_test_average_precision_score  \\\n",
       "0                                          0.812590   \n",
       "1                                          0.850360   \n",
       "2                                          0.824736   \n",
       "3                                          0.825685   \n",
       "4                                          0.848996   \n",
       "0                                          0.818933   \n",
       "1                                          0.819535   \n",
       "2                                          0.810926   \n",
       "3                                          0.815367   \n",
       "4                                          0.825282   \n",
       "0                                          0.528025   \n",
       "1                                          0.528025   \n",
       "2                                          0.528025   \n",
       "3                                          0.528025   \n",
       "4                                          0.528025   \n",
       "0                                          0.787230   \n",
       "1                                          0.761732   \n",
       "2                                          0.776272   \n",
       "3                                          0.793115   \n",
       "4                                          0.732940   \n",
       "0                                          0.666911   \n",
       "1                                          0.666911   \n",
       "2                                          0.668361   \n",
       "3                                          0.666911   \n",
       "4                                          0.666911   \n",
       "\n",
       "   bace_regression_valid_pearsonr  bace_regression_valid_rmse  \\\n",
       "0                        0.025686                    0.520232   \n",
       "1                        0.041414                    0.524236   \n",
       "2                        0.034139                    0.508618   \n",
       "3                        0.062565                    0.510056   \n",
       "4                        0.043745                    0.524860   \n",
       "0                        0.386013                    0.526491   \n",
       "1                        0.351971                    0.519460   \n",
       "2                        0.380552                    0.522898   \n",
       "3                        0.380487                    0.528667   \n",
       "4                        0.394321                    0.535069   \n",
       "0                        0.200680                    0.572452   \n",
       "1                        0.162325                    0.574779   \n",
       "2                        0.162855                    0.579915   \n",
       "3                        0.140878                    0.578404   \n",
       "4                        0.183911                    0.573742   \n",
       "0                        0.157970                    0.567084   \n",
       "1                        0.143197                    0.574159   \n",
       "2                        0.152992                    0.570695   \n",
       "3                        0.201737                    0.575481   \n",
       "4                        0.165314                    0.565029   \n",
       "0                        0.152212                    0.597335   \n",
       "1                        0.152158                    0.597264   \n",
       "2                        0.152103                    0.597348   \n",
       "3                        0.152051                    0.597339   \n",
       "4                        0.152146                    0.597347   \n",
       "\n",
       "   bace_regression_test_pearsonr  bace_regression_test_rmse  \\\n",
       "0                       0.775713                   1.088148   \n",
       "1                       0.767800                   1.093925   \n",
       "2                       0.786691                   1.080424   \n",
       "3                       0.773089                   1.074092   \n",
       "4                       0.775766                   1.103782   \n",
       "0                       0.696960                   1.066217   \n",
       "1                       0.698363                   1.084981   \n",
       "2                       0.706767                   1.103609   \n",
       "3                       0.683448                   1.126033   \n",
       "4                       0.699458                   1.130868   \n",
       "0                       0.796274                   1.072090   \n",
       "1                       0.780949                   1.108798   \n",
       "2                       0.730097                   1.170887   \n",
       "3                       0.633925                   1.221884   \n",
       "4                       0.803196                   1.074786   \n",
       "0                       0.570271                   1.169818   \n",
       "1                       0.435992                   1.234423   \n",
       "2                       0.554201                   1.159993   \n",
       "3                       0.656452                   1.105892   \n",
       "4                       0.623580                   1.143062   \n",
       "0                       0.344723                   1.262163   \n",
       "1                       0.344934                   1.262140   \n",
       "2                       0.344833                   1.262163   \n",
       "3                       0.344969                   1.262159   \n",
       "4                       0.344777                   1.262157   \n",
       "\n",
       "   bbbp_valid_roc_auc_score  bbbp_valid_average_precision_score  ...  \\\n",
       "0                  0.953416                            0.954161  ...   \n",
       "1                  0.664596                            0.673363  ...   \n",
       "2                  0.953028                            0.955238  ...   \n",
       "3                  0.955648                            0.955838  ...   \n",
       "4                  0.733307                            0.715206  ...   \n",
       "0                  0.646060                            0.700208  ...   \n",
       "1                  0.647807                            0.701861  ...   \n",
       "2                  0.651203                            0.702432  ...   \n",
       "3                  0.649845                            0.700853  ...   \n",
       "4                  0.650718                            0.703735  ...   \n",
       "0                  0.587636                            0.643216  ...   \n",
       "1                  0.587539                            0.643112  ...   \n",
       "2                  0.587636                            0.643216  ...   \n",
       "3                  0.587636                            0.643359  ...   \n",
       "4                  0.587539                            0.643178  ...   \n",
       "0                  0.948564                            0.950652  ...   \n",
       "1                  0.953319                            0.956929  ...   \n",
       "2                  0.948467                            0.948413  ...   \n",
       "3                  0.950602                            0.950087  ...   \n",
       "4                  0.946817                            0.944321  ...   \n",
       "0                  0.957298                            0.948095  ...   \n",
       "1                  0.958754                            0.948394  ...   \n",
       "2                  0.958269                            0.948493  ...   \n",
       "3                  0.958172                            0.948613  ...   \n",
       "4                  0.956425                            0.944765  ...   \n",
       "\n",
       "   delaney_test_rmse  lipo_valid_pearsonr  lipo_valid_rmse  \\\n",
       "0           0.557614             0.587488         0.814128   \n",
       "1           0.587209             0.608315         0.799419   \n",
       "2           0.577331             0.577650         0.821567   \n",
       "3           0.534699             0.566758         0.828631   \n",
       "4           0.551188             0.585450         0.815250   \n",
       "0           1.089734             0.675606         0.744013   \n",
       "1           1.089348             0.658490         0.759977   \n",
       "2           1.089461             0.651133         0.768026   \n",
       "3           1.089637             0.675172         0.744739   \n",
       "4           1.090029             0.694749         0.729115   \n",
       "0           0.786764             0.559995         0.841933   \n",
       "1           0.786426             0.580993         0.833033   \n",
       "2           0.786868             0.550857         0.851559   \n",
       "3           0.785166             0.557717         0.841385   \n",
       "4           0.784732             0.567456         0.840772   \n",
       "0           0.500234             0.594244         0.810215   \n",
       "1           0.494843             0.635426         0.778865   \n",
       "2           0.506093             0.629760         0.781795   \n",
       "3           0.492666             0.604261         0.802144   \n",
       "4           0.511693             0.590478         0.813702   \n",
       "0           0.506494             0.700273         0.742192   \n",
       "1           0.513124             0.718443         0.734897   \n",
       "2           0.513691             0.740373         0.711280   \n",
       "3           0.511006             0.687219         0.751247   \n",
       "4           0.504182             0.689844         0.758536   \n",
       "\n",
       "   lipo_test_pearsonr  lipo_test_rmse  tox21_valid_roc_auc_score  \\\n",
       "0            0.469805        0.812314                   0.717914   \n",
       "1            0.510296        0.795680                   0.769175   \n",
       "2            0.477865        0.817874                   0.756778   \n",
       "3            0.488899        0.813623                   0.747083   \n",
       "4            0.474445        0.818551                   0.739490   \n",
       "0            0.611014        0.727990                   0.695908   \n",
       "1            0.588983        0.742809                   0.698181   \n",
       "2            0.580118        0.746829                   0.708219   \n",
       "3            0.606664        0.733963                   0.706460   \n",
       "4            0.626268        0.723935                   0.714203   \n",
       "0            0.535669        0.785855                   0.776896   \n",
       "1            0.556836        0.774574                   0.775566   \n",
       "2            0.494188        0.807679                   0.785690   \n",
       "3            0.519508        0.791108                   0.761024   \n",
       "4            0.504600        0.806044                   0.752874   \n",
       "0            0.500075        0.802838                   0.793926   \n",
       "1            0.533525        0.788924                   0.782387   \n",
       "2            0.523192        0.791424                   0.775523   \n",
       "3            0.490747        0.821000                   0.768703   \n",
       "4            0.517507        0.790631                   0.774708   \n",
       "0            0.647553        0.722768                   0.704272   \n",
       "1            0.675877        0.713733                   0.707962   \n",
       "2            0.693528        0.700368                   0.704744   \n",
       "3            0.636140        0.726191                   0.706889   \n",
       "4            0.634108        0.739025                   0.701527   \n",
       "\n",
       "   tox21_valid_average_precision_score  tox21_test_roc_auc_score  \\\n",
       "0                             0.319912                  0.745829   \n",
       "1                             0.383500                  0.731151   \n",
       "2                             0.390135                  0.743138   \n",
       "3                             0.349745                  0.738784   \n",
       "4                             0.368941                  0.726993   \n",
       "0                             0.389212                  0.708303   \n",
       "1                             0.351627                  0.718822   \n",
       "2                             0.392658                  0.722614   \n",
       "3                             0.336662                  0.723910   \n",
       "4                             0.384258                  0.739811   \n",
       "0                             0.473188                  0.739567   \n",
       "1                             0.400353                  0.755174   \n",
       "2                             0.438065                  0.727971   \n",
       "3                             0.414390                  0.756984   \n",
       "4                             0.425464                  0.749450   \n",
       "0                             0.476944                  0.772005   \n",
       "1                             0.424622                  0.716963   \n",
       "2                             0.429804                  0.749743   \n",
       "3                             0.416913                  0.741719   \n",
       "4                             0.429777                  0.745976   \n",
       "0                             0.409440                  0.732374   \n",
       "1                             0.413216                  0.737756   \n",
       "2                             0.413110                  0.736484   \n",
       "3                             0.418142                  0.738539   \n",
       "4                             0.412342                  0.732032   \n",
       "\n",
       "   tox21_test_average_precision_score  run_name  \n",
       "0                            0.285211    run_11  \n",
       "1                            0.302215    run_11  \n",
       "2                            0.261230    run_11  \n",
       "3                            0.259383    run_11  \n",
       "4                            0.269691    run_11  \n",
       "0                            0.330024    run_19  \n",
       "1                            0.373326    run_19  \n",
       "2                            0.316314    run_19  \n",
       "3                            0.288643    run_19  \n",
       "4                            0.314118    run_19  \n",
       "0                            0.306432    run_38  \n",
       "1                            0.306817    run_38  \n",
       "2                            0.305062    run_38  \n",
       "3                            0.295736    run_38  \n",
       "4                            0.296878    run_38  \n",
       "0                            0.315820    run_39  \n",
       "1                            0.319807    run_39  \n",
       "2                            0.281322    run_39  \n",
       "3                            0.324869    run_39  \n",
       "4                            0.338969    run_39  \n",
       "0                            0.329506    run_45  \n",
       "1                            0.335231    run_45  \n",
       "2                            0.332703    run_45  \n",
       "3                            0.331947    run_45  \n",
       "4                            0.328458    run_45  \n",
       "\n",
       "[25 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a4d3ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>bace_classification_valid_roc_auc_score_mean</th>\n",
       "      <th>bace_classification_valid_average_precision_score_mean</th>\n",
       "      <th>bace_classification_valid_roc_auc_score_std</th>\n",
       "      <th>bace_classification_valid_average_precision_score_std</th>\n",
       "      <th>bace_classification_test_roc_auc_score_mean</th>\n",
       "      <th>bace_classification_test_average_precision_score_mean</th>\n",
       "      <th>bace_classification_test_roc_auc_score_std</th>\n",
       "      <th>bace_classification_test_average_precision_score_std</th>\n",
       "      <th>bace_regression_valid_pearsonr_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>lipo_test_pearsonr_std</th>\n",
       "      <th>lipo_test_rmse_std</th>\n",
       "      <th>tox21_valid_roc_auc_score_mean</th>\n",
       "      <th>tox21_valid_average_precision_score_mean</th>\n",
       "      <th>tox21_valid_roc_auc_score_std</th>\n",
       "      <th>tox21_valid_average_precision_score_std</th>\n",
       "      <th>tox21_test_roc_auc_score_mean</th>\n",
       "      <th>tox21_test_average_precision_score_mean</th>\n",
       "      <th>tox21_test_roc_auc_score_std</th>\n",
       "      <th>tox21_test_average_precision_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.674591</td>\n",
       "      <td>0.732636</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>0.009263</td>\n",
       "      <td>0.793152</td>\n",
       "      <td>0.832473</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014461</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.746088</td>\n",
       "      <td>0.362447</td>\n",
       "      <td>0.017237</td>\n",
       "      <td>0.025387</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.275546</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.016156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.676475</td>\n",
       "      <td>0.669169</td>\n",
       "      <td>0.008083</td>\n",
       "      <td>0.013194</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.818009</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.378669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.704594</td>\n",
       "      <td>0.370884</td>\n",
       "      <td>0.006716</td>\n",
       "      <td>0.022498</td>\n",
       "      <td>0.722692</td>\n",
       "      <td>0.324485</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.027839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.480384</td>\n",
       "      <td>0.581494</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.407790</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022283</td>\n",
       "      <td>0.012488</td>\n",
       "      <td>0.770410</td>\n",
       "      <td>0.430292</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>0.024791</td>\n",
       "      <td>0.745829</td>\n",
       "      <td>0.302185</td>\n",
       "      <td>0.010798</td>\n",
       "      <td>0.004848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.666098</td>\n",
       "      <td>0.686661</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>0.722500</td>\n",
       "      <td>0.770258</td>\n",
       "      <td>0.045955</td>\n",
       "      <td>0.021503</td>\n",
       "      <td>0.164242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015542</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>0.779049</td>\n",
       "      <td>0.435612</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.745281</td>\n",
       "      <td>0.316157</td>\n",
       "      <td>0.017602</td>\n",
       "      <td>0.019095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.613539</td>\n",
       "      <td>0.640570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560181</td>\n",
       "      <td>0.667201</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.152134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023401</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.705079</td>\n",
       "      <td>0.413250</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>0.331569</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.002399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  run_name  bace_classification_valid_roc_auc_score_mean  \\\n",
       "0   run_11                                      0.674591   \n",
       "1   run_19                                      0.676475   \n",
       "2   run_38                                      0.480384   \n",
       "3   run_39                                      0.666098   \n",
       "4   run_45                                      0.613539   \n",
       "\n",
       "   bace_classification_valid_average_precision_score_mean  \\\n",
       "0                                           0.732636        \n",
       "1                                           0.669169        \n",
       "2                                           0.581494        \n",
       "3                                           0.686661        \n",
       "4                                           0.640570        \n",
       "\n",
       "   bace_classification_valid_roc_auc_score_std  \\\n",
       "0                                     0.014858   \n",
       "1                                     0.008083   \n",
       "2                                     0.000142   \n",
       "3                                     0.009845   \n",
       "4                                     0.000000   \n",
       "\n",
       "   bace_classification_valid_average_precision_score_std  \\\n",
       "0                                           0.009263       \n",
       "1                                           0.013194       \n",
       "2                                           0.000095       \n",
       "3                                           0.009544       \n",
       "4                                           0.000000       \n",
       "\n",
       "   bace_classification_test_roc_auc_score_mean  \\\n",
       "0                                     0.793152   \n",
       "1                                     0.784493   \n",
       "2                                     0.407790   \n",
       "3                                     0.722500   \n",
       "4                                     0.560181   \n",
       "\n",
       "   bace_classification_test_average_precision_score_mean  \\\n",
       "0                                           0.832473       \n",
       "1                                           0.818009       \n",
       "2                                           0.528025       \n",
       "3                                           0.770258       \n",
       "4                                           0.667201       \n",
       "\n",
       "   bace_classification_test_roc_auc_score_std  \\\n",
       "0                                    0.013913   \n",
       "1                                    0.004532   \n",
       "2                                    0.000000   \n",
       "3                                    0.045955   \n",
       "4                                    0.000072   \n",
       "\n",
       "   bace_classification_test_average_precision_score_std  \\\n",
       "0                                           0.014793      \n",
       "1                                           0.004759      \n",
       "2                                           0.000000      \n",
       "3                                           0.021503      \n",
       "4                                           0.000580      \n",
       "\n",
       "   bace_regression_valid_pearsonr_mean  ...  lipo_test_pearsonr_std  \\\n",
       "0                             0.041510  ...                0.014461   \n",
       "1                             0.378669  ...                0.016360   \n",
       "2                             0.170130  ...                0.022283   \n",
       "3                             0.164242  ...                0.015542   \n",
       "4                             0.152134  ...                0.023401   \n",
       "\n",
       "   lipo_test_rmse_std  tox21_valid_roc_auc_score_mean  \\\n",
       "0            0.008315                        0.746088   \n",
       "1            0.008643                        0.704594   \n",
       "2            0.012488                        0.770410   \n",
       "3            0.012064                        0.779049   \n",
       "4            0.012898                        0.705079   \n",
       "\n",
       "   tox21_valid_average_precision_score_mean  tox21_valid_roc_auc_score_std  \\\n",
       "0                                  0.362447                       0.017237   \n",
       "1                                  0.370884                       0.006716   \n",
       "2                                  0.430292                       0.011813   \n",
       "3                                  0.435612                       0.008611   \n",
       "4                                  0.413250                       0.002234   \n",
       "\n",
       "   tox21_valid_average_precision_score_std  tox21_test_roc_auc_score_mean  \\\n",
       "0                                 0.025387                       0.737179   \n",
       "1                                 0.022498                       0.722692   \n",
       "2                                 0.024791                       0.745829   \n",
       "3                                 0.021197                       0.745281   \n",
       "4                                 0.002803                       0.735437   \n",
       "\n",
       "   tox21_test_average_precision_score_mean  tox21_test_roc_auc_score_std  \\\n",
       "0                                 0.275546                      0.007113   \n",
       "1                                 0.324485                      0.010164   \n",
       "2                                 0.302185                      0.010798   \n",
       "3                                 0.316157                      0.017602   \n",
       "4                                 0.331569                      0.002723   \n",
       "\n",
       "   tox21_test_average_precision_score_std  \n",
       "0                                0.016156  \n",
       "1                                0.027839  \n",
       "2                                0.004848  \n",
       "3                                0.019095  \n",
       "4                                0.002399  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14d9f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_avg_df = pd.merge(left=df, right=df_avg, on='run_name')\n",
    "# combined_avg_df['run_name'] = combined_avg_df['run_name'].apply(lambda x: f\"mlm_{x}\")\n",
    "\n",
    "combined_all_df = pd.merge(left=df, right=df_all, on='run_name')\n",
    "# combined_all_df['run_name'] = combined_all_df['run_name'].apply(lambda x: f\"mlm_{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28325e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>min_eval_loss</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>attention_probs_dropout_prob</th>\n",
       "      <th>hidden_dropout_prob</th>\n",
       "      <th>intermediate_size</th>\n",
       "      <th>num_attention_heads</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>pretraining_task</th>\n",
       "      <th>...</th>\n",
       "      <th>lipo_test_pearsonr_std</th>\n",
       "      <th>lipo_test_rmse_std</th>\n",
       "      <th>tox21_valid_roc_auc_score_mean</th>\n",
       "      <th>tox21_valid_average_precision_score_mean</th>\n",
       "      <th>tox21_valid_roc_auc_score_std</th>\n",
       "      <th>tox21_valid_average_precision_score_std</th>\n",
       "      <th>tox21_test_roc_auc_score_mean</th>\n",
       "      <th>tox21_test_average_precision_score_mean</th>\n",
       "      <th>tox21_test_roc_auc_score_std</th>\n",
       "      <th>tox21_test_average_precision_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.168913</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.704594</td>\n",
       "      <td>0.370884</td>\n",
       "      <td>0.006716</td>\n",
       "      <td>0.022498</td>\n",
       "      <td>0.722692</td>\n",
       "      <td>0.324485</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.027839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014461</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.746088</td>\n",
       "      <td>0.362447</td>\n",
       "      <td>0.017237</td>\n",
       "      <td>0.025387</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.275546</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.016156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.421750</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015542</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>0.779049</td>\n",
       "      <td>0.435612</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.745281</td>\n",
       "      <td>0.316157</td>\n",
       "      <td>0.017602</td>\n",
       "      <td>0.019095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.386785</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022283</td>\n",
       "      <td>0.012488</td>\n",
       "      <td>0.770410</td>\n",
       "      <td>0.430292</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>0.024791</td>\n",
       "      <td>0.745829</td>\n",
       "      <td>0.302185</td>\n",
       "      <td>0.010798</td>\n",
       "      <td>0.004848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.136374</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023401</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.705079</td>\n",
       "      <td>0.413250</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>0.331569</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.002399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  run_name  min_eval_loss  hidden_size  attention_probs_dropout_prob  \\\n",
       "0   run_19       0.168913           57                         0.129   \n",
       "1   run_11       0.578779          112                         0.118   \n",
       "2   run_39       0.421750          209                         0.176   \n",
       "3   run_38       0.386785          126                         0.109   \n",
       "4   run_45       0.136374          384                         0.109   \n",
       "\n",
       "   hidden_dropout_prob  intermediate_size  num_attention_heads  \\\n",
       "0                0.139              10476                    3   \n",
       "1                0.183               4844                    8   \n",
       "2                0.128               3968                   11   \n",
       "3                0.279                456                    3   \n",
       "4                0.144                464                   12   \n",
       "\n",
       "   num_hidden_layers  learning_rate pretraining_task  ...  \\\n",
       "0                  5       0.000058          77M-MLM  ...   \n",
       "1                  5       0.000002          77M-MLM  ...   \n",
       "2                  3       0.000002          77M-MLM  ...   \n",
       "3                  2       0.000021          77M-MLM  ...   \n",
       "4                  3       0.000141          77M-MLM  ...   \n",
       "\n",
       "   lipo_test_pearsonr_std  lipo_test_rmse_std  tox21_valid_roc_auc_score_mean  \\\n",
       "0                0.016360            0.008643                        0.704594   \n",
       "1                0.014461            0.008315                        0.746088   \n",
       "2                0.015542            0.012064                        0.779049   \n",
       "3                0.022283            0.012488                        0.770410   \n",
       "4                0.023401            0.012898                        0.705079   \n",
       "\n",
       "   tox21_valid_average_precision_score_mean  tox21_valid_roc_auc_score_std  \\\n",
       "0                                  0.370884                       0.006716   \n",
       "1                                  0.362447                       0.017237   \n",
       "2                                  0.435612                       0.008611   \n",
       "3                                  0.430292                       0.011813   \n",
       "4                                  0.413250                       0.002234   \n",
       "\n",
       "   tox21_valid_average_precision_score_std  tox21_test_roc_auc_score_mean  \\\n",
       "0                                 0.022498                       0.722692   \n",
       "1                                 0.025387                       0.737179   \n",
       "2                                 0.021197                       0.745281   \n",
       "3                                 0.024791                       0.745829   \n",
       "4                                 0.002803                       0.735437   \n",
       "\n",
       "   tox21_test_average_precision_score_mean  tox21_test_roc_auc_score_std  \\\n",
       "0                                 0.324485                      0.010164   \n",
       "1                                 0.275546                      0.007113   \n",
       "2                                 0.316157                      0.017602   \n",
       "3                                 0.302185                      0.010798   \n",
       "4                                 0.331569                      0.002723   \n",
       "\n",
       "   tox21_test_average_precision_score_std  \n",
       "0                                0.027839  \n",
       "1                                0.016156  \n",
       "2                                0.019095  \n",
       "3                                0.004848  \n",
       "4                                0.002399  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28be99fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>min_eval_loss</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>attention_probs_dropout_prob</th>\n",
       "      <th>hidden_dropout_prob</th>\n",
       "      <th>intermediate_size</th>\n",
       "      <th>num_attention_heads</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>pretraining_task</th>\n",
       "      <th>...</th>\n",
       "      <th>delaney_test_pearsonr</th>\n",
       "      <th>delaney_test_rmse</th>\n",
       "      <th>lipo_valid_pearsonr</th>\n",
       "      <th>lipo_valid_rmse</th>\n",
       "      <th>lipo_test_pearsonr</th>\n",
       "      <th>lipo_test_rmse</th>\n",
       "      <th>tox21_valid_roc_auc_score</th>\n",
       "      <th>tox21_valid_average_precision_score</th>\n",
       "      <th>tox21_test_roc_auc_score</th>\n",
       "      <th>tox21_test_average_precision_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.168913</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437073</td>\n",
       "      <td>1.089734</td>\n",
       "      <td>0.675606</td>\n",
       "      <td>0.744013</td>\n",
       "      <td>0.611014</td>\n",
       "      <td>0.727990</td>\n",
       "      <td>0.695908</td>\n",
       "      <td>0.389212</td>\n",
       "      <td>0.708303</td>\n",
       "      <td>0.330024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.168913</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439334</td>\n",
       "      <td>1.089348</td>\n",
       "      <td>0.658490</td>\n",
       "      <td>0.759977</td>\n",
       "      <td>0.588983</td>\n",
       "      <td>0.742809</td>\n",
       "      <td>0.698181</td>\n",
       "      <td>0.351627</td>\n",
       "      <td>0.718822</td>\n",
       "      <td>0.373326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.168913</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439593</td>\n",
       "      <td>1.089461</td>\n",
       "      <td>0.651133</td>\n",
       "      <td>0.768026</td>\n",
       "      <td>0.580118</td>\n",
       "      <td>0.746829</td>\n",
       "      <td>0.708219</td>\n",
       "      <td>0.392658</td>\n",
       "      <td>0.722614</td>\n",
       "      <td>0.316314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.168913</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439891</td>\n",
       "      <td>1.089637</td>\n",
       "      <td>0.675172</td>\n",
       "      <td>0.744739</td>\n",
       "      <td>0.606664</td>\n",
       "      <td>0.733963</td>\n",
       "      <td>0.706460</td>\n",
       "      <td>0.336662</td>\n",
       "      <td>0.723910</td>\n",
       "      <td>0.288643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_19</td>\n",
       "      <td>0.168913</td>\n",
       "      <td>57</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.139</td>\n",
       "      <td>10476</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440339</td>\n",
       "      <td>1.090029</td>\n",
       "      <td>0.694749</td>\n",
       "      <td>0.729115</td>\n",
       "      <td>0.626268</td>\n",
       "      <td>0.723935</td>\n",
       "      <td>0.714203</td>\n",
       "      <td>0.384258</td>\n",
       "      <td>0.739811</td>\n",
       "      <td>0.314118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841089</td>\n",
       "      <td>0.557614</td>\n",
       "      <td>0.587488</td>\n",
       "      <td>0.814128</td>\n",
       "      <td>0.469805</td>\n",
       "      <td>0.812314</td>\n",
       "      <td>0.717914</td>\n",
       "      <td>0.319912</td>\n",
       "      <td>0.745829</td>\n",
       "      <td>0.285211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820132</td>\n",
       "      <td>0.587209</td>\n",
       "      <td>0.608315</td>\n",
       "      <td>0.799419</td>\n",
       "      <td>0.510296</td>\n",
       "      <td>0.795680</td>\n",
       "      <td>0.769175</td>\n",
       "      <td>0.383500</td>\n",
       "      <td>0.731151</td>\n",
       "      <td>0.302215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836423</td>\n",
       "      <td>0.577331</td>\n",
       "      <td>0.577650</td>\n",
       "      <td>0.821567</td>\n",
       "      <td>0.477865</td>\n",
       "      <td>0.817874</td>\n",
       "      <td>0.756778</td>\n",
       "      <td>0.390135</td>\n",
       "      <td>0.743138</td>\n",
       "      <td>0.261230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857394</td>\n",
       "      <td>0.534699</td>\n",
       "      <td>0.566758</td>\n",
       "      <td>0.828631</td>\n",
       "      <td>0.488899</td>\n",
       "      <td>0.813623</td>\n",
       "      <td>0.747083</td>\n",
       "      <td>0.349745</td>\n",
       "      <td>0.738784</td>\n",
       "      <td>0.259383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>run_11</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>112</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853444</td>\n",
       "      <td>0.551188</td>\n",
       "      <td>0.585450</td>\n",
       "      <td>0.815250</td>\n",
       "      <td>0.474445</td>\n",
       "      <td>0.818551</td>\n",
       "      <td>0.739490</td>\n",
       "      <td>0.368941</td>\n",
       "      <td>0.726993</td>\n",
       "      <td>0.269691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.421750</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877545</td>\n",
       "      <td>0.500234</td>\n",
       "      <td>0.594244</td>\n",
       "      <td>0.810215</td>\n",
       "      <td>0.500075</td>\n",
       "      <td>0.802838</td>\n",
       "      <td>0.793926</td>\n",
       "      <td>0.476944</td>\n",
       "      <td>0.772005</td>\n",
       "      <td>0.315820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.421750</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882910</td>\n",
       "      <td>0.494843</td>\n",
       "      <td>0.635426</td>\n",
       "      <td>0.778865</td>\n",
       "      <td>0.533525</td>\n",
       "      <td>0.788924</td>\n",
       "      <td>0.782387</td>\n",
       "      <td>0.424622</td>\n",
       "      <td>0.716963</td>\n",
       "      <td>0.319807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.421750</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>0.506093</td>\n",
       "      <td>0.629760</td>\n",
       "      <td>0.781795</td>\n",
       "      <td>0.523192</td>\n",
       "      <td>0.791424</td>\n",
       "      <td>0.775523</td>\n",
       "      <td>0.429804</td>\n",
       "      <td>0.749743</td>\n",
       "      <td>0.281322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.421750</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879640</td>\n",
       "      <td>0.492666</td>\n",
       "      <td>0.604261</td>\n",
       "      <td>0.802144</td>\n",
       "      <td>0.490747</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0.768703</td>\n",
       "      <td>0.416913</td>\n",
       "      <td>0.741719</td>\n",
       "      <td>0.324869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.421750</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867558</td>\n",
       "      <td>0.511693</td>\n",
       "      <td>0.590478</td>\n",
       "      <td>0.813702</td>\n",
       "      <td>0.517507</td>\n",
       "      <td>0.790631</td>\n",
       "      <td>0.774708</td>\n",
       "      <td>0.429777</td>\n",
       "      <td>0.745976</td>\n",
       "      <td>0.338969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.386785</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696347</td>\n",
       "      <td>0.786764</td>\n",
       "      <td>0.559995</td>\n",
       "      <td>0.841933</td>\n",
       "      <td>0.535669</td>\n",
       "      <td>0.785855</td>\n",
       "      <td>0.776896</td>\n",
       "      <td>0.473188</td>\n",
       "      <td>0.739567</td>\n",
       "      <td>0.306432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.386785</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696972</td>\n",
       "      <td>0.786426</td>\n",
       "      <td>0.580993</td>\n",
       "      <td>0.833033</td>\n",
       "      <td>0.556836</td>\n",
       "      <td>0.774574</td>\n",
       "      <td>0.775566</td>\n",
       "      <td>0.400353</td>\n",
       "      <td>0.755174</td>\n",
       "      <td>0.306817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.386785</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698309</td>\n",
       "      <td>0.786868</td>\n",
       "      <td>0.550857</td>\n",
       "      <td>0.851559</td>\n",
       "      <td>0.494188</td>\n",
       "      <td>0.807679</td>\n",
       "      <td>0.785690</td>\n",
       "      <td>0.438065</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>0.305062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.386785</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697257</td>\n",
       "      <td>0.785166</td>\n",
       "      <td>0.557717</td>\n",
       "      <td>0.841385</td>\n",
       "      <td>0.519508</td>\n",
       "      <td>0.791108</td>\n",
       "      <td>0.761024</td>\n",
       "      <td>0.414390</td>\n",
       "      <td>0.756984</td>\n",
       "      <td>0.295736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.386785</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698279</td>\n",
       "      <td>0.784732</td>\n",
       "      <td>0.567456</td>\n",
       "      <td>0.840772</td>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.806044</td>\n",
       "      <td>0.752874</td>\n",
       "      <td>0.425464</td>\n",
       "      <td>0.749450</td>\n",
       "      <td>0.296878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.136374</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874943</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.700273</td>\n",
       "      <td>0.742192</td>\n",
       "      <td>0.647553</td>\n",
       "      <td>0.722768</td>\n",
       "      <td>0.704272</td>\n",
       "      <td>0.409440</td>\n",
       "      <td>0.732374</td>\n",
       "      <td>0.329506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.136374</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870767</td>\n",
       "      <td>0.513124</td>\n",
       "      <td>0.718443</td>\n",
       "      <td>0.734897</td>\n",
       "      <td>0.675877</td>\n",
       "      <td>0.713733</td>\n",
       "      <td>0.707962</td>\n",
       "      <td>0.413216</td>\n",
       "      <td>0.737756</td>\n",
       "      <td>0.335231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.136374</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870452</td>\n",
       "      <td>0.513691</td>\n",
       "      <td>0.740373</td>\n",
       "      <td>0.711280</td>\n",
       "      <td>0.693528</td>\n",
       "      <td>0.700368</td>\n",
       "      <td>0.704744</td>\n",
       "      <td>0.413110</td>\n",
       "      <td>0.736484</td>\n",
       "      <td>0.332703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.136374</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871235</td>\n",
       "      <td>0.511006</td>\n",
       "      <td>0.687219</td>\n",
       "      <td>0.751247</td>\n",
       "      <td>0.636140</td>\n",
       "      <td>0.726191</td>\n",
       "      <td>0.706889</td>\n",
       "      <td>0.418142</td>\n",
       "      <td>0.738539</td>\n",
       "      <td>0.331947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.136374</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>77M-MLM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875762</td>\n",
       "      <td>0.504182</td>\n",
       "      <td>0.689844</td>\n",
       "      <td>0.758536</td>\n",
       "      <td>0.634108</td>\n",
       "      <td>0.739025</td>\n",
       "      <td>0.701527</td>\n",
       "      <td>0.412342</td>\n",
       "      <td>0.732032</td>\n",
       "      <td>0.328458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_name  min_eval_loss  hidden_size  attention_probs_dropout_prob  \\\n",
       "0    run_19       0.168913           57                         0.129   \n",
       "1    run_19       0.168913           57                         0.129   \n",
       "2    run_19       0.168913           57                         0.129   \n",
       "3    run_19       0.168913           57                         0.129   \n",
       "4    run_19       0.168913           57                         0.129   \n",
       "5    run_11       0.578779          112                         0.118   \n",
       "6    run_11       0.578779          112                         0.118   \n",
       "7    run_11       0.578779          112                         0.118   \n",
       "8    run_11       0.578779          112                         0.118   \n",
       "9    run_11       0.578779          112                         0.118   \n",
       "10   run_39       0.421750          209                         0.176   \n",
       "11   run_39       0.421750          209                         0.176   \n",
       "12   run_39       0.421750          209                         0.176   \n",
       "13   run_39       0.421750          209                         0.176   \n",
       "14   run_39       0.421750          209                         0.176   \n",
       "15   run_38       0.386785          126                         0.109   \n",
       "16   run_38       0.386785          126                         0.109   \n",
       "17   run_38       0.386785          126                         0.109   \n",
       "18   run_38       0.386785          126                         0.109   \n",
       "19   run_38       0.386785          126                         0.109   \n",
       "20   run_45       0.136374          384                         0.109   \n",
       "21   run_45       0.136374          384                         0.109   \n",
       "22   run_45       0.136374          384                         0.109   \n",
       "23   run_45       0.136374          384                         0.109   \n",
       "24   run_45       0.136374          384                         0.109   \n",
       "\n",
       "    hidden_dropout_prob  intermediate_size  num_attention_heads  \\\n",
       "0                 0.139              10476                    3   \n",
       "1                 0.139              10476                    3   \n",
       "2                 0.139              10476                    3   \n",
       "3                 0.139              10476                    3   \n",
       "4                 0.139              10476                    3   \n",
       "5                 0.183               4844                    8   \n",
       "6                 0.183               4844                    8   \n",
       "7                 0.183               4844                    8   \n",
       "8                 0.183               4844                    8   \n",
       "9                 0.183               4844                    8   \n",
       "10                0.128               3968                   11   \n",
       "11                0.128               3968                   11   \n",
       "12                0.128               3968                   11   \n",
       "13                0.128               3968                   11   \n",
       "14                0.128               3968                   11   \n",
       "15                0.279                456                    3   \n",
       "16                0.279                456                    3   \n",
       "17                0.279                456                    3   \n",
       "18                0.279                456                    3   \n",
       "19                0.279                456                    3   \n",
       "20                0.144                464                   12   \n",
       "21                0.144                464                   12   \n",
       "22                0.144                464                   12   \n",
       "23                0.144                464                   12   \n",
       "24                0.144                464                   12   \n",
       "\n",
       "    num_hidden_layers  learning_rate pretraining_task  ...  \\\n",
       "0                   5       0.000058          77M-MLM  ...   \n",
       "1                   5       0.000058          77M-MLM  ...   \n",
       "2                   5       0.000058          77M-MLM  ...   \n",
       "3                   5       0.000058          77M-MLM  ...   \n",
       "4                   5       0.000058          77M-MLM  ...   \n",
       "5                   5       0.000002          77M-MLM  ...   \n",
       "6                   5       0.000002          77M-MLM  ...   \n",
       "7                   5       0.000002          77M-MLM  ...   \n",
       "8                   5       0.000002          77M-MLM  ...   \n",
       "9                   5       0.000002          77M-MLM  ...   \n",
       "10                  3       0.000002          77M-MLM  ...   \n",
       "11                  3       0.000002          77M-MLM  ...   \n",
       "12                  3       0.000002          77M-MLM  ...   \n",
       "13                  3       0.000002          77M-MLM  ...   \n",
       "14                  3       0.000002          77M-MLM  ...   \n",
       "15                  2       0.000021          77M-MLM  ...   \n",
       "16                  2       0.000021          77M-MLM  ...   \n",
       "17                  2       0.000021          77M-MLM  ...   \n",
       "18                  2       0.000021          77M-MLM  ...   \n",
       "19                  2       0.000021          77M-MLM  ...   \n",
       "20                  3       0.000141          77M-MLM  ...   \n",
       "21                  3       0.000141          77M-MLM  ...   \n",
       "22                  3       0.000141          77M-MLM  ...   \n",
       "23                  3       0.000141          77M-MLM  ...   \n",
       "24                  3       0.000141          77M-MLM  ...   \n",
       "\n",
       "    delaney_test_pearsonr  delaney_test_rmse  lipo_valid_pearsonr  \\\n",
       "0                0.437073           1.089734             0.675606   \n",
       "1                0.439334           1.089348             0.658490   \n",
       "2                0.439593           1.089461             0.651133   \n",
       "3                0.439891           1.089637             0.675172   \n",
       "4                0.440339           1.090029             0.694749   \n",
       "5                0.841089           0.557614             0.587488   \n",
       "6                0.820132           0.587209             0.608315   \n",
       "7                0.836423           0.577331             0.577650   \n",
       "8                0.857394           0.534699             0.566758   \n",
       "9                0.853444           0.551188             0.585450   \n",
       "10               0.877545           0.500234             0.594244   \n",
       "11               0.882910           0.494843             0.635426   \n",
       "12               0.877953           0.506093             0.629760   \n",
       "13               0.879640           0.492666             0.604261   \n",
       "14               0.867558           0.511693             0.590478   \n",
       "15               0.696347           0.786764             0.559995   \n",
       "16               0.696972           0.786426             0.580993   \n",
       "17               0.698309           0.786868             0.550857   \n",
       "18               0.697257           0.785166             0.557717   \n",
       "19               0.698279           0.784732             0.567456   \n",
       "20               0.874943           0.506494             0.700273   \n",
       "21               0.870767           0.513124             0.718443   \n",
       "22               0.870452           0.513691             0.740373   \n",
       "23               0.871235           0.511006             0.687219   \n",
       "24               0.875762           0.504182             0.689844   \n",
       "\n",
       "    lipo_valid_rmse  lipo_test_pearsonr  lipo_test_rmse  \\\n",
       "0          0.744013            0.611014        0.727990   \n",
       "1          0.759977            0.588983        0.742809   \n",
       "2          0.768026            0.580118        0.746829   \n",
       "3          0.744739            0.606664        0.733963   \n",
       "4          0.729115            0.626268        0.723935   \n",
       "5          0.814128            0.469805        0.812314   \n",
       "6          0.799419            0.510296        0.795680   \n",
       "7          0.821567            0.477865        0.817874   \n",
       "8          0.828631            0.488899        0.813623   \n",
       "9          0.815250            0.474445        0.818551   \n",
       "10         0.810215            0.500075        0.802838   \n",
       "11         0.778865            0.533525        0.788924   \n",
       "12         0.781795            0.523192        0.791424   \n",
       "13         0.802144            0.490747        0.821000   \n",
       "14         0.813702            0.517507        0.790631   \n",
       "15         0.841933            0.535669        0.785855   \n",
       "16         0.833033            0.556836        0.774574   \n",
       "17         0.851559            0.494188        0.807679   \n",
       "18         0.841385            0.519508        0.791108   \n",
       "19         0.840772            0.504600        0.806044   \n",
       "20         0.742192            0.647553        0.722768   \n",
       "21         0.734897            0.675877        0.713733   \n",
       "22         0.711280            0.693528        0.700368   \n",
       "23         0.751247            0.636140        0.726191   \n",
       "24         0.758536            0.634108        0.739025   \n",
       "\n",
       "    tox21_valid_roc_auc_score  tox21_valid_average_precision_score  \\\n",
       "0                    0.695908                             0.389212   \n",
       "1                    0.698181                             0.351627   \n",
       "2                    0.708219                             0.392658   \n",
       "3                    0.706460                             0.336662   \n",
       "4                    0.714203                             0.384258   \n",
       "5                    0.717914                             0.319912   \n",
       "6                    0.769175                             0.383500   \n",
       "7                    0.756778                             0.390135   \n",
       "8                    0.747083                             0.349745   \n",
       "9                    0.739490                             0.368941   \n",
       "10                   0.793926                             0.476944   \n",
       "11                   0.782387                             0.424622   \n",
       "12                   0.775523                             0.429804   \n",
       "13                   0.768703                             0.416913   \n",
       "14                   0.774708                             0.429777   \n",
       "15                   0.776896                             0.473188   \n",
       "16                   0.775566                             0.400353   \n",
       "17                   0.785690                             0.438065   \n",
       "18                   0.761024                             0.414390   \n",
       "19                   0.752874                             0.425464   \n",
       "20                   0.704272                             0.409440   \n",
       "21                   0.707962                             0.413216   \n",
       "22                   0.704744                             0.413110   \n",
       "23                   0.706889                             0.418142   \n",
       "24                   0.701527                             0.412342   \n",
       "\n",
       "    tox21_test_roc_auc_score  tox21_test_average_precision_score  \n",
       "0                   0.708303                            0.330024  \n",
       "1                   0.718822                            0.373326  \n",
       "2                   0.722614                            0.316314  \n",
       "3                   0.723910                            0.288643  \n",
       "4                   0.739811                            0.314118  \n",
       "5                   0.745829                            0.285211  \n",
       "6                   0.731151                            0.302215  \n",
       "7                   0.743138                            0.261230  \n",
       "8                   0.738784                            0.259383  \n",
       "9                   0.726993                            0.269691  \n",
       "10                  0.772005                            0.315820  \n",
       "11                  0.716963                            0.319807  \n",
       "12                  0.749743                            0.281322  \n",
       "13                  0.741719                            0.324869  \n",
       "14                  0.745976                            0.338969  \n",
       "15                  0.739567                            0.306432  \n",
       "16                  0.755174                            0.306817  \n",
       "17                  0.727971                            0.305062  \n",
       "18                  0.756984                            0.295736  \n",
       "19                  0.749450                            0.296878  \n",
       "20                  0.732374                            0.329506  \n",
       "21                  0.737756                            0.335231  \n",
       "22                  0.736484                            0.332703  \n",
       "23                  0.738539                            0.331947  \n",
       "24                  0.732032                            0.328458  \n",
       "\n",
       "[25 rows x 42 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "577d1c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_avg_df.to_csv('ft_results_combined.csv', index=False)\n",
    "combined_all_df.to_csv('ft_results_all_seeds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reverie_env_new] *",
   "language": "python",
   "name": "conda-env-reverie_env_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
